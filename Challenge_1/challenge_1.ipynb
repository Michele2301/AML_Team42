{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Challenge_1: Aerial Cactus-AML",
   "id": "be3c022e1a3c112d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T21:15:17.685796Z",
     "start_time": "2024-04-18T21:15:17.682625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "id": "8d12dabd2c81384b",
   "execution_count": 387,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Phase 1: Loading the data, analyzing it, doing feature engineering and creating the Loader",
   "id": "8e719abcd6683eb5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T21:15:17.716827Z",
     "start_time": "2024-04-18T21:15:17.708734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cactus Dataset model\n",
    "class CactusDataset(Dataset):\n",
    "    def __init__(self,train='./data/train/train',labels='./data/train.csv',transform=None,target_transform=None):\n",
    "        if labels is None:\n",
    "            self.df=None\n",
    "        else:\n",
    "            self.df=pd.read_csv(labels)\n",
    "        self.imgPath=train\n",
    "        self.transform=transform\n",
    "        self.target_transform=target_transform\n",
    "    def __len__(self):\n",
    "        # here you just need to return a single integer number as the length of your dataset, in your \n",
    "        #  case, number of images in your train folder or lines in csv file\n",
    "        if self.df is not None:\n",
    "            return len(self.df)\n",
    "        else:\n",
    "            return len(os.listdir(self.imgPath))\n",
    "    def __getitem__(self, idx):\n",
    "        # if we already have the labels we can use them to find the nth element otherwise we use the folder order. This is used for\n",
    "        # example when we have only a partial number of labels compared to the number of images or when we don't have them at all\n",
    "        img_path = os.path.join(self.imgPath, self.df['id'][idx] if self.df is not None else os.listdir(self.imgPath)[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.df is not None:\n",
    "            label = self.df['has_cactus'][idx]\n",
    "        else:\n",
    "            label = None\n",
    "        # we perform transformations if they are not None and the labels are not None\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform is not None and label is not None:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "    \n",
    "    # this function is used to get the distribution of the labels in the dataset\n",
    "    def label_distribution(self):\n",
    "        if self.df is not None:\n",
    "            return self.df['has_cactus'].value_counts(ascending=True).values\n",
    "        else:\n",
    "            return np.array([0,0])\n",
    "        \n",
    "class ConcatTransformDataset(Dataset):\n",
    "    def __init__(self, datasets):\n",
    "        self.datasets = datasets\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        dataset_idx, sample_idx = self._get_dataset_index(index)\n",
    "        image, label = self.datasets[dataset_idx][sample_idx]\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(len(dataset) for dataset in self.datasets)\n",
    "\n",
    "    def _get_dataset_index(self, index):\n",
    "        for i, dataset in enumerate(self.datasets):\n",
    "            if index < len(dataset):\n",
    "                return i, index\n",
    "            index -= len(dataset)\n",
    "        raise IndexError('Index out of range')"
   ],
   "id": "6edf2384edb09bd6",
   "execution_count": 388,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T21:15:17.746628Z",
     "start_time": "2024-04-18T21:15:17.732639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load data for displaying\n",
    "dataset=CactusDataset()\n",
    "# take the first sample from train_dataloader\n",
    "train_features, train_labels = dataset[10000]\n",
    "image_np = np.array(train_features)\n",
    "print(\"Image shape: \"+str(image_np.shape))\n",
    "print(\"Image python class\"+str(type(train_features)))\n",
    "print(\"Label: \"+str(train_labels))"
   ],
   "id": "b8826ca650e99f97",
   "execution_count": 389,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T21:15:17.901978Z",
     "start_time": "2024-04-18T21:15:17.748353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# show the image\n",
    "plt.imshow(image_np)"
   ],
   "id": "71ca919c7003ae70",
   "execution_count": 390,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T21:15:17.985594Z",
     "start_time": "2024-04-18T21:15:17.903198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "label_distribution = dataset.label_distribution() # they are sorted in ascending order\n",
    "print(label_distribution)\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie(label_distribution, labels=['no cactus','cactus'], autopct='%1.1f%%')\n",
    "plt.show()"
   ],
   "id": "1b137c14a6d6abc7",
   "execution_count": 391,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T21:15:17.992653Z",
     "start_time": "2024-04-18T21:15:17.988379Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"Number of train values: \"+str(dataset.__len__()))",
   "id": "b7acaba6545f4ac8",
   "execution_count": 392,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T21:15:18.234611Z",
     "start_time": "2024-04-18T21:15:17.994573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform_dataset = transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = CactusDataset(transform=transform_dataset)\n",
    "image, label = dataset[0]\n",
    "print(\"Image python class\"+str(type(image)))\n",
    "print(\"Image shape: \"+str(image.shape))\n",
    "# show the image\n",
    "plt.imshow(image.permute(1,2,0))"
   ],
   "id": "97db5bff212a55dd",
   "execution_count": 393,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T21:15:18.238539Z",
     "start_time": "2024-04-18T21:15:18.235771Z"
    }
   },
   "cell_type": "code",
   "source": "dataloader=DataLoader(dataset,batch_size=32,shuffle=True)",
   "id": "8a114828e6536b6e",
   "execution_count": 394,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T21:15:18.270311Z",
     "start_time": "2024-04-18T21:15:18.239843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i, (images, labels) in enumerate(dataloader):\n",
    "    print(\"Batch number: \"+str(i))\n",
    "    print(\"Batch images shape: \"+str(images.shape))\n",
    "    print(\"Batch labels shape: \"+str(labels.shape))\n",
    "    break"
   ],
   "id": "b423023edf5b599b",
   "execution_count": 395,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T21:15:18.357414Z",
     "start_time": "2024-04-18T21:15:18.271529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO we might want to add a network with the already labeled points to classify some image from the test set in order to arrive to a more balanced dataset\n",
    "# --------- DATA AUGMENTATION ---------\n",
    "# we want to place some data augmentation with the no cactus images\n",
    "transform_augmented = transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset_augmented = CactusDataset(transform=transform_augmented)\n",
    "# remove the has_cactus=1 images before augmentation and keep also the first row (id,has_cactus)\n",
    "dataset_augmented.df=dataset.df[dataset.df['has_cactus']==0]\n",
    "dataset_augmented.df=dataset_augmented.df.reset_index(drop=True)\n",
    "\n",
    "# print the size of the dataset\n",
    "print(\"Number of no cactus images: \"+str(dataset_augmented.__len__()))\n",
    "# create the data loader with both the augmented and the original dataset\n",
    "dataset_merged=ConcatTransformDataset([dataset,dataset_augmented])\n",
    "\n",
    "# print the size of the new dataset\n",
    "print(\"Number of train values: \"+str(dataset_augmented.__len__()))\n",
    "# redo statistics of the pie on the concatDataset\n",
    "label_distribution_augmented=dataset_augmented.label_distribution()\n",
    "label_distribution_concat=np.add(label_distribution,label_distribution_augmented)\n",
    "# print the new numbers\n",
    "print(\"Number of cactus images: \"+str(label_distribution_concat[1]))\n",
    "print(\"Number of no cactus images: \"+str(label_distribution_concat[0]))\n",
    "# plot the new pie\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie(label_distribution_concat, labels=['cactus','no cactus'], autopct='%1.1f%%')\n",
    "plt.show()"
   ],
   "id": "bc569977230810ae",
   "execution_count": 396,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T21:15:18.394830Z",
     "start_time": "2024-04-18T21:15:18.359480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --------- CREATING THE DATA LOADER AND TRAIN/VAL SPLIT ---------\n",
    "train_size = int(0.8 * len(dataset_merged))\n",
    "print(\"Train size: \" + str(train_size))\n",
    "test_size = len(dataset_merged) - train_size\n",
    "print(\"Test size: \" + str(test_size))\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset_merged, [train_size, test_size])\n",
    "\n",
    "# Retrieve the lengths of the datasets\n",
    "print(\"Merged dataset length: \" + str(len(dataset_merged)))\n",
    "print(\"Train dataset length: \" + str(len(train_dataset)))\n",
    "print(\"Validation dataset length: \" + str(len(val_dataset)))\n",
    "print(\"Augmented dataset length: \" + str(len(dataset_augmented)))\n",
    "\n",
    "# Create DataLoader for training and validation\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Print an item from the train_dataloader (torch tensor)\n",
    "for i, (images, labels) in enumerate(train_dataloader):\n",
    "    print(\"Batch number: \" + str(i))\n",
    "    print(\"Batch images shape: \" + str(images.shape))\n",
    "    break\n"
   ],
   "id": "2b50be15f297b226",
   "execution_count": 397,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " # Phase 2: defining the model",
   "id": "76cf552ec233ad5a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
