{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import CactusDataset\n",
    "from sklearn.metrics import roc_curve, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use_gpu = torch.cuda.is_available()\n",
    "#if use_gpu:\n",
    "#    print(\"Using CUDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 12250, 'val': 3500, 'test': 1750}\n",
      "3072\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../../../data/train/train'\n",
    "csv_file = '../../../data/train.csv'\n",
    "TRAIN = 'train'\n",
    "VAL = 'val'\n",
    "TEST = 'test'\n",
    "\n",
    "#set the transforms for the images\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "image_dataset = CactusDataset.CactusDataset(csv_file, data_dir, data_transforms)\n",
    "# split into train, eval, test\n",
    "train_size = int(0.7 * len(image_dataset))\n",
    "eval_size = int(0.2 * len(image_dataset))\n",
    "test_size = len(image_dataset) - train_size - eval_size\n",
    "train_dataset, eval_dataset, test_dataset = torch.utils.data.random_split(image_dataset, [train_size, eval_size, test_size])\n",
    "\n",
    "image_datasets = {TRAIN: train_dataset, VAL: eval_dataset, TEST: test_dataset}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in [TRAIN, VAL, TEST]}\n",
    "\n",
    "batch_sizes = {TRAIN: dataset_sizes[TRAIN], VAL: dataset_sizes[VAL], TEST: 64}\n",
    "\n",
    "dataloaders = {TRAIN: None, VAL: None, TEST: None}\n",
    "dataloaders[TRAIN] = DataLoader(image_datasets[TRAIN], batch_size=batch_sizes[TRAIN],\n",
    "                                             shuffle=True, num_workers=0)\n",
    "dataloaders[VAL] = DataLoader(image_datasets[VAL], batch_size=batch_sizes[VAL],\n",
    "                                             shuffle=False, num_workers=0)\n",
    "dataloaders[TEST] = DataLoader(image_datasets[TEST], batch_size=batch_sizes[TEST], shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "print(dataset_sizes)\n",
    "class_names = {0: 'No Cactus', 1: 'Cactus'}\n",
    "\n",
    "inputs, classes = next(iter(dataloaders[TRAIN]))\n",
    "\n",
    "n_features = 32 * 32 * 3\n",
    "\n",
    "print(n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "# f = wx + b, sigmoid at the end\n",
    "class LogisticRegression(nn.Module):\n",
    "\n",
    "    def __init__(self, n_input_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_predicted = torch.sigmoid(self.linear(x))\n",
    "        return y_predicted\n",
    "    \n",
    "model = LogisticRegression(n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, model_name, X_train, y_train, X_val, y_val, num_epochs=1000):\n",
    "    # training loop\n",
    "    num_epochs = num_epochs\n",
    "    accs_train = []\n",
    "    accs_val = []\n",
    "    aucs = []\n",
    "    best_fpr = []\n",
    "    best_tpr = []\n",
    "    best_auc = 0\n",
    "    best_acc = 0\n",
    "    #40k epoche runnate\n",
    "    for epoch in range(num_epochs):\n",
    "        #randomly horizontal flip the images in X_train\n",
    "        X_train = torch.tensor(X_train)\n",
    "        transform = transforms.Compose([transforms.RandomHorizontalFlip()])\n",
    "        X_train = transform(X_train)\n",
    "        # forward pass and loss\n",
    "        outputs = model(torch.tensor(X_train))\n",
    "        #make y_predicted and y_train of same shape\n",
    "        outputs = outputs.view(-1)\n",
    "\n",
    "        preds = outputs.round()\n",
    "        acc_train = (preds == y_train).sum() / y_train.shape[0]\n",
    "        accs_train.append(acc_train)\n",
    "\n",
    "        loss = criterion(outputs, y_train.float())\n",
    "        \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # updates\n",
    "        optimizer.step()\n",
    "        \n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(torch.tensor(X_val))  # no need to call model.forward()\n",
    "            y_predicted_cls = outputs.round()   # round off to nearest class\n",
    "            #flatten\n",
    "            y_val = y_val.view(-1)\n",
    "            y_predicted_cls = y_predicted_cls.view(-1)\n",
    "            #Compute accuracy\n",
    "            acc = (y_predicted_cls == y_val).sum() / y_val.shape[0]   # accuracy\n",
    "            accs_val.append(acc)\n",
    "            #Compute AUC\n",
    "            fpr, tpr, _ = roc_curve(y_val, outputs)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            aucs.append(roc_auc)\n",
    "            if roc_auc > best_auc:\n",
    "                best_auc = roc_auc\n",
    "                epoch_best = epoch\n",
    "                best_fpr = fpr\n",
    "                best_tpr = tpr\n",
    "            \n",
    "    \n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                epoch_best = epoch\n",
    "                #save the best model weights with info about PCA compoenents\n",
    "                torch.save(model.state_dict(), f'../../../data/LR/'+str(model_name)+f'weights_best.pt')\n",
    "            if epoch % 100 == 0:\n",
    "                print(f'Epoch: {epoch}, Loss: {loss.item()}, Accuracy on val: {acc}')\n",
    "    return accs_train, accs_val, aucs, best_fpr, best_tpr, best_auc, epoch_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "X_train = []\n",
    "y_train = []\n",
    "for images, labels in dataloaders[TRAIN]:\n",
    "    images = images.view(-1, n_features)\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "X_train = torch.cat(X_train, dim=0)\n",
    "y_train = torch.cat(y_train, dim=0)\n",
    "X_val = []\n",
    "y_val = []\n",
    "for images, labels in dataloaders[VAL]:\n",
    "    images = images.view(-1, n_features)\n",
    "    X_val.append(images)\n",
    "    y_val.append(labels)\n",
    "X_val = torch.cat(X_val, dim=0)\n",
    "y_val = torch.cat(y_val, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model for 1000 epochs\n",
    "train_model(model, criterion, optimizer, 'logistic_regression', X_train, y_train, X_val, y_val, num_epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for images, labels in dataloaders[TRAIN]:\n",
    "    images = images.view(-1, n_features)\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "X_train = torch.cat(X_train, dim=0)\n",
    "y_train = torch.cat(y_train, dim=0)\n",
    "X_val = []\n",
    "y_val = []\n",
    "for images, labels in dataloaders[VAL]:\n",
    "    images = images.view(-1, n_features)\n",
    "    X_val.append(images)\n",
    "    y_val.append(labels)\n",
    "X_val = torch.cat(X_val, dim=0)\n",
    "y_val = torch.cat(y_val, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retain only n_componenets feature with highest variance using PCA\n",
    "n_components = 625\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train.detach().numpy())\n",
    "X_val_pca = pca.transform(X_val.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(X_train_pca.shape[1])\n",
    "# Loss and optimizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69432/2208340002.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = model(torch.tensor(X_train))\n",
      "/tmp/ipykernel_69432/2208340002.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100, loss = 0.5503\n",
      "tensor(0.7800)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69432/2208340002.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train)\n",
      "/tmp/ipykernel_69432/2208340002.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = model(torch.tensor(X_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 200, loss = 0.5112\n",
      "tensor(0.7926)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69432/2208340002.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train)\n",
      "/tmp/ipykernel_69432/2208340002.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = model(torch.tensor(X_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 300, loss = 0.4807\n",
      "tensor(0.8046)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69432/2208340002.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train)\n",
      "/tmp/ipykernel_69432/2208340002.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = model(torch.tensor(X_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 400, loss = 0.4607\n",
      "tensor(0.8114)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69432/2208340002.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train)\n",
      "/tmp/ipykernel_69432/2208340002.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = model(torch.tensor(X_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 500, loss = 0.4419\n",
      "tensor(0.8151)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69432/2208340002.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train)\n",
      "/tmp/ipykernel_69432/2208340002.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = model(torch.tensor(X_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 600, loss = 0.4228\n",
      "tensor(0.8243)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69432/2208340002.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train)\n",
      "/tmp/ipykernel_69432/2208340002.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = model(torch.tensor(X_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 700, loss = 0.4118\n",
      "tensor(0.8271)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69432/2208340002.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train)\n",
      "/tmp/ipykernel_69432/2208340002.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = model(torch.tensor(X_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 800, loss = 0.4023\n",
      "tensor(0.8326)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69432/2208340002.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train)\n",
      "/tmp/ipykernel_69432/2208340002.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = model(torch.tensor(X_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 900, loss = 0.3904\n",
      "tensor(0.8349)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69432/2208340002.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train)\n",
      "/tmp/ipykernel_69432/2208340002.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = model(torch.tensor(X_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1000, loss = 0.3850\n",
      "tensor(0.8383)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69432/2208340002.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train)\n",
      "/tmp/ipykernel_69432/2208340002.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = model(torch.tensor(X_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1100, loss = 0.3743\n",
      "tensor(0.8434)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69432/2208340002.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train)\n",
      "/tmp/ipykernel_69432/2208340002.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = model(torch.tensor(X_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1200, loss = 0.3705\n",
      "tensor(0.8471)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69432/2208340002.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train)\n",
      "/tmp/ipykernel_69432/2208340002.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = model(torch.tensor(X_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1300, loss = 0.3643\n",
      "tensor(0.8526)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69432/2208340002.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train)\n",
      "/tmp/ipykernel_69432/2208340002.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = model(torch.tensor(X_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1400, loss = 0.3562\n",
      "tensor(0.8569)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69432/2208340002.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train)\n",
      "/tmp/ipykernel_69432/2208340002.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = model(torch.tensor(X_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1500, loss = 0.3511\n",
      "tensor(0.8586)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69432/2208340002.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train)\n",
      "/tmp/ipykernel_69432/2208340002.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = model(torch.tensor(X_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1600, loss = 0.3496\n",
      "tensor(0.8606)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69432/2208340002.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train)\n",
      "/tmp/ipykernel_69432/2208340002.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = model(torch.tensor(X_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1700, loss = 0.3462\n",
      "tensor(0.8629)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69432/2208340002.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train)\n",
      "/tmp/ipykernel_69432/2208340002.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = model(torch.tensor(X_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1800, loss = 0.3377\n",
      "tensor(0.8649)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69432/2208340002.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train)\n",
      "/tmp/ipykernel_69432/2208340002.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = model(torch.tensor(X_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1900, loss = 0.3345\n",
      "tensor(0.8663)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69432/2208340002.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train)\n",
      "/tmp/ipykernel_69432/2208340002.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = model(torch.tensor(X_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2000, loss = 0.3353\n",
      "tensor(0.8686)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69432/2208340002.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train)\n",
      "/tmp/ipykernel_69432/2208340002.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = model(torch.tensor(X_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2100, loss = 0.3318\n",
      "tensor(0.8709)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69432/2208340002.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train)\n",
      "/tmp/ipykernel_69432/2208340002.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = model(torch.tensor(X_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2200, loss = 0.3261\n",
      "tensor(0.8726)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69432/2208340002.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train)\n",
      "/tmp/ipykernel_69432/2208340002.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = model(torch.tensor(X_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2300, loss = 0.3233\n",
      "tensor(0.8731)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69432/2208340002.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train)\n",
      "/tmp/ipykernel_69432/2208340002.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = model(torch.tensor(X_train))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[168], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Train model using pca features\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m accs_train, accs_val, aucs, best_fpr, best_tpr, best_auc, epoch_best \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogistic_regression_pca\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_pca\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_pca\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#plot accuracy train vs val\u001b[39;00m\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(accs_train, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[167], line 18\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, model_name, X_train, y_train, X_val, y_val, num_epochs)\u001b[0m\n\u001b[1;32m     16\u001b[0m X_train \u001b[38;5;241m=\u001b[39m transform(X_train)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# forward pass and loss\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#make y_predicted and y_train of same shape\u001b[39;00m\n\u001b[1;32m     20\u001b[0m outputs \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/asi/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/asi/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[158], line 10\u001b[0m, in \u001b[0;36mLogisticRegression.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 10\u001b[0m     y_predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y_predicted\n",
      "File \u001b[0;32m~/miniconda3/envs/asi/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/asi/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/asi/lib/python3.12/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Train model using pca features\n",
    "accs_train, accs_val, aucs, best_fpr, best_tpr, best_auc, epoch_best = train_model(model, criterion, optimizer, 'logistic_regression_pca', X_train_pca, y_train, X_val_pca, y_val, num_epochs=10000)\n",
    "#plot accuracy train vs val\n",
    "plt.plot(accs_train, label='train')\n",
    "plt.plot(accs_val, label='val')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#plot AUC\n",
    "plt.plot(aucs)\n",
    "plt.show()\n",
    "#plot ROC\n",
    "plt.plot(best_fpr, best_tpr)\n",
    "plt.show()\n",
    "print('Best AUC:', best_auc)\n",
    "print('Best epoch:', epoch_best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR using only grayscale values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 12250, 'val': 3500, 'test': 1750}\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "data_dir = '../../../data/train/train'\n",
    "csv_file = '../../../data/train.csv'\n",
    "TRAIN = 'train'\n",
    "VAL = 'val'\n",
    "TEST = 'test'\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "image_dataset = CactusDataset.CactusDataset(csv_file, data_dir, data_transforms)\n",
    "# split into train, eval, test\n",
    "train_size = int(0.7 * len(image_dataset))\n",
    "eval_size = int(0.2 * len(image_dataset))\n",
    "test_size = len(image_dataset) - train_size - eval_size\n",
    "train_dataset, eval_dataset, test_dataset = torch.utils.data.random_split(image_dataset, [train_size, eval_size, test_size])\n",
    "\n",
    "image_datasets = {TRAIN: train_dataset, VAL: eval_dataset, TEST: test_dataset}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in [TRAIN, VAL, TEST]}\n",
    "\n",
    "batch_sizes = {TRAIN: dataset_sizes[TRAIN], VAL: dataset_sizes[VAL], TEST: 64}\n",
    "\n",
    "dataloaders = {TRAIN: None, VAL: None, TEST: None}\n",
    "dataloaders[TRAIN] = DataLoader(image_datasets[TRAIN], batch_size=batch_sizes[TRAIN],\n",
    "                                             shuffle=True, num_workers=0)\n",
    "dataloaders[VAL] = DataLoader(image_datasets[VAL], batch_size=batch_sizes[VAL],\n",
    "                                             shuffle=False, num_workers=0)\n",
    "dataloaders[TEST] = DataLoader(image_datasets[TEST], batch_size=batch_sizes[TEST], shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "print(dataset_sizes)\n",
    "class_names = {0: 'No Cactus', 1: 'Cactus'}\n",
    "\n",
    "inputs, classes = next(iter(dataloaders[TRAIN]))\n",
    "\n",
    "n_features = 32 * 32\n",
    "\n",
    "print(n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12250, 1024])\n",
      "torch.Size([12250, 1024])\n",
      "torch.Size([12250])\n",
      "torch.Size([3500, 1024])\n",
      "torch.Size([3500])\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "X_train = []\n",
    "y_train = []\n",
    "for images, labels in dataloaders[TRAIN]:\n",
    "    images = images.view(-1, n_features)\n",
    "    print(images.shape)\n",
    "    X_train.append(images)\n",
    "    y_train.append(labels)\n",
    "X_train = torch.cat(X_train, dim=0)\n",
    "y_train = torch.cat(y_train, dim=0)\n",
    "X_val = []\n",
    "y_val = []\n",
    "for images, labels in dataloaders[VAL]:\n",
    "    images = images.view(-1, n_features)\n",
    "    X_val.append(images)\n",
    "    y_val.append(labels)\n",
    "X_val = torch.cat(X_val, dim=0)\n",
    "y_val = torch.cat(y_val, dim=0)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(n_features)\n",
    "# Loss and optimizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69432/2598064429.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_predicted = model(torch.tensor(X_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100, loss = 0.5691\n",
      "Accuracy: 0.7460\n",
      "TP: 2611.0, TN: 0.0, FP: 889.0, FN: 0.0\n",
      "Precision: 0.7460, Recall: 1.0000\n",
      "tensor(0.7460)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69432/2598064429.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_predicted = model(torch.tensor(X_val))  # no need to call model.forward()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 200, loss = 0.5616\n",
      "Accuracy: 0.7460\n",
      "TP: 2611.0, TN: 0.0, FP: 889.0, FN: 0.0\n",
      "Precision: 0.7460, Recall: 1.0000\n",
      "tensor(0.7460)\n",
      "epoch: 300, loss = 0.5546\n",
      "Accuracy: 0.7460\n",
      "TP: 2611.0, TN: 0.0, FP: 889.0, FN: 0.0\n",
      "Precision: 0.7460, Recall: 1.0000\n",
      "tensor(0.7460)\n",
      "epoch: 400, loss = 0.5482\n",
      "Accuracy: 0.7460\n",
      "TP: 2611.0, TN: 0.0, FP: 889.0, FN: 0.0\n",
      "Precision: 0.7460, Recall: 1.0000\n",
      "tensor(0.7460)\n",
      "epoch: 500, loss = 0.5422\n",
      "Accuracy: 0.7460\n",
      "TP: 2611.0, TN: 0.0, FP: 889.0, FN: 0.0\n",
      "Precision: 0.7460, Recall: 1.0000\n",
      "tensor(0.7460)\n",
      "epoch: 600, loss = 0.5367\n",
      "Accuracy: 0.7463\n",
      "TP: 2611.0, TN: 1.0, FP: 888.0, FN: 0.0\n",
      "Precision: 0.7462, Recall: 1.0000\n",
      "tensor(0.7463)\n",
      "epoch: 700, loss = 0.5315\n",
      "Accuracy: 0.7463\n",
      "TP: 2611.0, TN: 1.0, FP: 888.0, FN: 0.0\n",
      "Precision: 0.7462, Recall: 1.0000\n",
      "tensor(0.7463)\n",
      "epoch: 800, loss = 0.5267\n",
      "Accuracy: 0.7463\n",
      "TP: 2610.0, TN: 2.0, FP: 887.0, FN: 1.0\n",
      "Precision: 0.7464, Recall: 0.9996\n",
      "tensor(0.7463)\n",
      "epoch: 900, loss = 0.5222\n",
      "Accuracy: 0.7463\n",
      "TP: 2609.0, TN: 3.0, FP: 886.0, FN: 2.0\n",
      "Precision: 0.7465, Recall: 0.9992\n",
      "tensor(0.7463)\n",
      "epoch: 1000, loss = 0.5180\n",
      "Accuracy: 0.7463\n",
      "TP: 2607.0, TN: 5.0, FP: 884.0, FN: 4.0\n",
      "Precision: 0.7468, Recall: 0.9985\n",
      "tensor(0.7463)\n",
      "Best accuracy: 0.7462857365608215 at epoch: 599\n"
     ]
    }
   ],
   "source": [
    "train_model(model, criterion, optimizer, 'logistic_regression_grayscale', X_train, y_train, X_val, y_val, num_epochs=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
