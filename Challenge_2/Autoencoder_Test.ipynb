{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T10:12:09.445930Z",
     "start_time": "2024-05-25T10:12:09.254611Z"
    }
   },
   "source": [
    "%reset -f\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wandb\n",
    "\n",
    "\n",
    "from customDatasets.audioDataset import AudioDataset\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T10:12:09.450139Z",
     "start_time": "2024-05-25T10:12:09.447581Z"
    }
   },
   "source": [
    "# free gpu\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T10:12:09.456225Z",
     "start_time": "2024-05-25T10:12:09.451231Z"
    }
   },
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size, encoding_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, encoding_dim),\n",
    "            nn.BatchNorm1d(encoding_dim),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, input_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T10:12:09.466993Z",
     "start_time": "2024-05-25T10:12:09.458377Z"
    }
   },
   "source": [
    "# test for deciding the mels parameters\n",
    "from utils.audioUtils import AudioUtil\n",
    "from torchaudio import transforms\n",
    "import torch\n",
    "audio_file = \"./data/train/normal_id_00_00000000.wav\"\n",
    "\n",
    "aud = AudioUtil.open(audio_file)\n",
    "sig, sr = aud\n",
    "mel = transforms.MelSpectrogram(sr, n_fft=1000, hop_length=501, n_mels=128)\n",
    "spec = mel(sig)\n",
    "ampl = transforms.AmplitudeToDB(top_db=80)\n",
    "spec = ampl(spec)\n",
    "\n",
    "\n",
    "print(spec.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 320])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T10:12:09.480144Z",
     "start_time": "2024-05-25T10:12:09.468211Z"
    }
   },
   "source": [
    "def train_model(model, train_dl, val_dl, test_dl, criterion, optimizer, device, wandb=None, epochs=5,step_size=5):\n",
    "    lr_scheduler=torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=0.5)\n",
    "    best_val_loss = np.inf\n",
    "    for epoch in range(epochs):\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        for inputs, labels in train_dl:\n",
    "            model.train()\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, inputs.view(inputs.size(0), -1))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "        lr_scheduler.step()\n",
    "        print(f'Epoch[{epoch + 1}/{epochs}], Train loss: {np.average(train_losses): .4f}')\n",
    "        \n",
    "        for inputs, labels in val_dl:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                inputs = inputs.view(inputs.shape[0]*inputs.shape[1], -1)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, inputs)\n",
    "                val_losses.append(loss.item())\n",
    "        print(f'Epoch[{epoch + 1}/{epochs}], Val loss: {np.average(val_losses): .4f}')\n",
    "        if np.average(val_losses) < best_val_loss:\n",
    "            best_val_loss = np.average(val_losses)\n",
    " \n",
    "        full_scores = []\n",
    "        full_labels = []\n",
    "        for inputs, labels in test_dl:\n",
    "            inputs, labels = inputs.to(CONFIG[\"device\"]), labels.to(CONFIG[\"device\"])\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                tmp_scores = []\n",
    "                for idx in range (10):\n",
    "                    outputs = model(inputs[:, idx, :, :])\n",
    "                    mse = torch.sum((outputs - inputs[:, idx, :, :].view(inputs.size(0), -1)) ** 2, dim=1, keepdim=True) / outputs.shape[1]\n",
    "                    tmp_scores.append(mse)\n",
    "\n",
    "                scores = torch.cat(tmp_scores, dim=1)\n",
    "                scores = torch.max(scores, dim=1).values\n",
    "\n",
    "                full_scores.append(scores)\n",
    "                full_labels.append(labels)\n",
    "        \n",
    "        full_labels = torch.cat([label for label in full_labels])\n",
    "        full_scores = torch.cat([score for score in full_scores])\n",
    "        fpr, tpr, _ = roc_curve(full_labels.cpu().detach(), full_scores.cpu().detach(), pos_label=0)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        print(roc_auc)\n",
    "        if wandb:\n",
    "            wandb.log({\"roc_auc test\": roc_auc, \"val_loss\": np.average(val_losses), \"train_loss\": np.average(train_losses)})\n",
    "    return best_val_loss"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T10:14:21.535217Z",
     "start_time": "2024-05-25T10:12:09.481534Z"
    }
   },
   "source": [
    "def set_seed(seed = 42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "CONFIG = {\n",
    "    \"seed\": 42,\n",
    "    \"epochs\": 500,\n",
    "    \"num_classes\": 2,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"train_batch_size\": 32,\n",
    "    \"val_batch_size\": 16,\n",
    "    \"test_batch_size\": 128,\n",
    "    \"criterion\": nn.MSELoss(),\n",
    "    \"device\":\n",
    "        torch.device(\n",
    "            \"cuda:0\" if torch.cuda.is_available()\n",
    "            else \"mps\" if torch.backends.mps.is_available()\n",
    "            else \"cpu\"\n",
    "        )\n",
    "}\n",
    "\n",
    "set_seed(CONFIG['seed'])\n",
    "\n",
    "data_path = \"./data/train/\"\n",
    "data_path_test = \"./data/test/\"\n",
    "\n",
    "\n",
    "meta_train_df = pd.read_csv(\"./data/train.csv\")\n",
    "meta_test_df = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "train_df = meta_train_df[['filename', 'is_normal', 'machine_id']]\n",
    "range_train, range_test = train_test_split(range(len(train_df)), test_size=0.2, train_size=0.8, random_state=None, shuffle=True, stratify=meta_train_df['machine_id'])\n",
    "val_df = train_df.iloc[range_test].reset_index(drop=True)\n",
    "train_df = train_df.iloc[range_train].reset_index(drop=True)\n",
    "train_dataset = AudioDataset(train_df, data_path,in_memory=True, sgram_type=\"mel\", augment=True, split_sgram=True)\n",
    "val_dataset = AudioDataset(val_df, data_path,in_memory=True, sgram_type=\"mel\", augment=False, test_mode=True)\n",
    "test_df = meta_test_df[['filename', 'is_normal', 'machine_id']]\n",
    "test_dataset = AudioDataset(test_df, data_path_test, in_memory=True, sgram_type=\"mel\", augment=False, test_mode=True)\n",
    "\n",
    "train_ds = train_dataset\n",
    "val_ds = val_dataset\n",
    "test_ds = test_dataset\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=CONFIG['train_batch_size'], shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=CONFIG['val_batch_size'], shuffle=False)\n",
    "test_dl = DataLoader(test_ds, batch_size=CONFIG[\"test_batch_size\"], shuffle=False)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T10:14:21.651286Z",
     "start_time": "2024-05-25T10:14:21.538160Z"
    }
   },
   "source": [
    "inputs, labels = next(iter(train_dl))\n",
    "\n",
    "print(inputs.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 32, 128])\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T10:14:22.809745Z",
     "start_time": "2024-05-25T10:14:21.652499Z"
    }
   },
   "source": [
    "input_size = next(iter(train_dl))[0].shape[1] * next(iter(train_dl))[0].shape[2] * next(iter(train_dl))[0].shape[3]\n",
    "model = Autoencoder(input_size, encoding_dim=128)\n",
    "model = model.to(CONFIG[\"device\"])\n",
    "optimizer = optim.Adam(model.parameters(), lr=CONFIG[\"learning_rate\"], weight_decay=1e-5)"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T10:14:26.904003Z",
     "start_time": "2024-05-25T10:14:22.811110Z"
    }
   },
   "source": [
    "# compute metrics\n",
    "inputs_cat=[]\n",
    "train_dataset.test_mode = True\n",
    "for inputs, labels in train_dl:\n",
    "    print(inputs.shape)\n",
    "    inputs_cat.append(inputs)\n",
    "inputs_cat = torch.cat([input for input in inputs_cat])\n",
    "inputs_cat = inputs_cat.view(-1,inputs_cat.shape[2],inputs_cat.shape[3])\n",
    "print(inputs_cat.shape)\n",
    "train_dataset.test_mode = False"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([8, 10, 32, 128])\n",
      "torch.Size([18960, 32, 128])\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T10:14:27.268865Z",
     "start_time": "2024-05-25T10:14:26.906497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# compute the mean and std value for each frequency of the batch_sizexchannelxtimexfrequecy\n",
    "mean = torch.mean(inputs_cat, dim=0)\n",
    "std = torch.std(inputs_cat, dim=0)\n",
    "print(mean.shape)\n",
    "print(std.shape)\n",
    "train_dataset.mean = mean\n",
    "train_dataset.std = std\n",
    "val_dataset.mean = mean\n",
    "val_dataset.std = std\n",
    "test_dataset.mean = mean\n",
    "test_dataset.std = std"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T10:14:31.745552Z",
     "start_time": "2024-05-25T10:14:27.270122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# compute metrics\n",
    "inputs_cat=[]\n",
    "train_dataset.test_mode = True\n",
    "for inputs, labels in train_dl:\n",
    "    print(inputs.shape)\n",
    "    inputs_cat.append(inputs)\n",
    "inputs_cat = torch.cat([input for input in inputs_cat])\n",
    "inputs_cat = inputs_cat.view(-1,inputs_cat.shape[2],inputs_cat.shape[3])\n",
    "print(inputs_cat.shape)\n",
    "train_dataset.test_mode = False"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([32, 10, 32, 128])\n",
      "torch.Size([8, 10, 32, 128])\n",
      "torch.Size([18960, 32, 128])\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T10:14:32.254397Z",
     "start_time": "2024-05-25T10:14:31.746577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# compute the min and max value for each frequency of the batch_sizexchannelxtimexfrequecy\n",
    "min = torch.min(inputs_cat, dim=0).values\n",
    "max = torch.max(inputs_cat, dim=0).values\n",
    "print(max.shape)\n",
    "print(min.shape)\n",
    "train_dataset.min = min\n",
    "train_dataset.max = max\n",
    "val_dataset.min = min\n",
    "val_dataset.max = max\n",
    "test_dataset.min = min\n",
    "test_dataset.max = max"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T10:14:34.002952Z",
     "start_time": "2024-05-25T10:14:32.255384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# init wandb\n",
    "wandb.login()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mmicheleferrero9\u001B[0m (\u001B[33mai-ml-monitor\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T10:15:04.127190Z",
     "start_time": "2024-05-25T10:15:02.487459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"Challenge_2_AETimeFrames\",\n",
    ")\n",
    "# save all the parameters from the CONFIG dict\n",
    "wandb.config.update(CONFIG)\n",
    "print(wandb.config)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/media/michele/HardDisk/SCUOLA/Universita/Magistrale/Secondo_anno/AML/AML_Team42/Challenge_2/wandb/run-20240525_121502-1n0qwlt8</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ai-ml-monitor/Challenge_2_AETimeFrames/runs/1n0qwlt8/workspace' target=\"_blank\">fresh-haze-1</a></strong> to <a href='https://wandb.ai/ai-ml-monitor/Challenge_2_AETimeFrames' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/ai-ml-monitor/Challenge_2_AETimeFrames' target=\"_blank\">https://wandb.ai/ai-ml-monitor/Challenge_2_AETimeFrames</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/ai-ml-monitor/Challenge_2_AETimeFrames/runs/1n0qwlt8/workspace' target=\"_blank\">https://wandb.ai/ai-ml-monitor/Challenge_2_AETimeFrames/runs/1n0qwlt8/workspace</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seed': 42, 'epochs': 500, 'num_classes': 2, 'learning_rate': 0.001, 'train_batch_size': 32, 'val_batch_size': 16, 'test_batch_size': 128, 'criterion': 'MSELoss()', 'device': 'cuda:0'}\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-05-25T10:15:04.129695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training=True\n",
    "input_size = next(iter(train_dl))[0].shape[1] * next(iter(train_dl))[0].shape[2] * next(iter(train_dl))[0].shape[3]\n",
    "measures = []\n",
    "# testing emb space size\n",
    "if training:\n",
    "    for emb_space_size in [32, 64, 128, 256, 512]:\n",
    "        model = Autoencoder(encoding_dim=emb_space_size, input_size=input_size)\n",
    "        model = model.to(CONFIG[\"device\"])\n",
    "        optimizer = optim.Adam(model.parameters(), lr=CONFIG[\"learning_rate\"])\n",
    "        measures.append(train_model(model, train_dl, val_dl, test_dl, CONFIG[\"criterion\"], optimizer, CONFIG[\"device\"], epochs=100))\n",
    "    for emb_space_size, measure in zip([32, 64, 128, 256, 512], measures):\n",
    "        print(f\"Emb space size: {emb_space_size}, Train loss: {measure[0]}, Val loss: {measure[1]}, ROC AUC: {measure[2]}\")\n",
    "for (measure, emb_space_size) in zip(measures, [32, 64, 128, 256, 512]):\n",
    "    print({\"emb_space_size\": emb_space_size, \"val_loss\": measure})"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/100], Train loss:  0.0407\n",
      "Epoch[1/100], Val loss:  0.0119\n",
      "0.763491468997087\n",
      "Epoch[2/100], Train loss:  0.0120\n",
      "Epoch[2/100], Val loss:  0.0168\n",
      "0.648635039533916\n",
      "Epoch[3/100], Train loss:  0.0121\n",
      "Epoch[3/100], Val loss:  0.0109\n",
      "0.7445443196004995\n",
      "Epoch[4/100], Train loss:  0.0111\n",
      "Epoch[4/100], Val loss:  0.0106\n",
      "0.7336662505201831\n",
      "Epoch[5/100], Train loss:  0.0110\n",
      "Epoch[5/100], Val loss:  0.0100\n",
      "0.7836745734498545\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# take the best one and train it for more epochs\n",
    "if training:\n",
    "    emb_space_measures=[32, 64, 128, 256, 512]\n",
    "    model = Autoencoder(encoding_dim=emb_space_measures[np.argmax([measure[2] for measure in measures])], input_size=input_size)\n",
    "    model = model.to(CONFIG[\"device\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "training=True\n",
    "if training:\n",
    "    train_model(model, train_dl, val_dl, test_dl, CONFIG[\"criterion\"], optimizer, CONFIG[\"device\"], wandb, CONFIG[\"epochs\"], 50)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
