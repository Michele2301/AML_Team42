{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T13:38:08.498429Z",
     "start_time": "2024-05-19T13:38:08.298418Z"
    }
   },
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "\n",
    "from customDatasets.audioDataset import AudioDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T13:38:08.502395Z",
     "start_time": "2024-05-19T13:38:08.499728Z"
    }
   },
   "outputs": [],
   "source": [
    "# free gpu\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T13:38:08.521976Z",
     "start_time": "2024-05-19T13:38:08.503618Z"
    }
   },
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size, encoding_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, encoding_dim),\n",
    "            nn.BatchNorm1d(encoding_dim),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, input_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T13:38:08.534222Z",
     "start_time": "2024-05-19T13:38:08.524055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 320])\n"
     ]
    }
   ],
   "source": [
    "# test for deciding the mels parameters\n",
    "from utils.audioUtils import AudioUtil\n",
    "from torchaudio import transforms\n",
    "import torch\n",
    "audio_file = \"./data/train/normal_id_00_00000000.wav\"\n",
    "\n",
    "aud = AudioUtil.open(audio_file)\n",
    "sig, sr = aud\n",
    "mel = transforms.MelSpectrogram(sr, n_fft=1000, hop_length=501, n_mels=128)\n",
    "spec = mel(sig)\n",
    "ampl = transforms.AmplitudeToDB(top_db=80)\n",
    "spec = ampl(spec)\n",
    "\n",
    "\n",
    "print(spec.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T13:38:08.545812Z",
     "start_time": "2024-05-19T13:38:08.535582Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, original_train_dataset, train_dl, val_dl, test_dl, criterion, optimizer, device, epochs=5,step_size=5):\n",
    "    #lr_scheduler=torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=0.1)\n",
    "    for epoch in range(epochs):\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        #Set augmentation to true for training phase\n",
    "        original_train_dataset.augment = True\n",
    "        for inputs, labels in train_dl:\n",
    "            model.train()\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, inputs.view(inputs.size(0), -1))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "        #lr_scheduler.step()\n",
    "        print(f'Epoch[{epoch + 1}/{epochs}], Train loss: {np.average(train_losses): .4f}')\n",
    "        \n",
    "        #Disable augmentation for validation phase\n",
    "        #original_train_dataset.augment = False\n",
    "        #for inputs, labels in val_dl:\n",
    "        #    model.eval()\n",
    "        #    with torch.no_grad():\n",
    "        #        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        #        outputs = model(inputs)\n",
    "        #        loss = criterion(outputs, inputs.view(inputs.size(0), -1))\n",
    "        #        val_losses.append(loss.item())\n",
    "        #print(f'Epoch[{epoch + 1}/{epochs}], Val loss: {np.average(val_losses): .4f}')\n",
    " \n",
    "        #scores = []\n",
    "        #full_labels = []\n",
    "        #for inputs, labels in test_dl:\n",
    "        #    model.eval()\n",
    "        #    with torch.no_grad():\n",
    "        #        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        #        tmp_scores = []\n",
    "        #        for idx in range (10):\n",
    "        #            len = int(inputs.shape[2] / 10)\n",
    "        #            inputs = inputs[:, 0, len*idx:len*idx+len, :]\n",
    "        #            outputs = model(inputs)\n",
    "        #            mse = torch.sum((outputs - inputs.view(inputs.size(0), -1)) ** 2, dim=1) / outputs.shape[1]\n",
    "        #            print(mse.shape)\n",
    "        #            tmp_scores.append(mse)\n",
    "        #        scores.append(torch.max(mse, dim=1))\n",
    "        #        full_labels.append(labels)\n",
    "\n",
    "        full_scores = []\n",
    "        full_labels = []\n",
    "        for inputs, labels in test_dl:\n",
    "            inputs, labels = inputs.to(CONFIG[\"device\"]), labels.to(CONFIG[\"device\"])\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                tmp_scores = []\n",
    "                for idx in range (10):\n",
    "                    outputs = model(inputs[:, idx, :, :])\n",
    "                    mse = torch.sum((outputs - inputs[:, idx, :, :].view(inputs.size(0), -1)) ** 2, dim=1, keepdim=True) / outputs.shape[1]\n",
    "                    tmp_scores.append(mse)\n",
    "\n",
    "                scores = torch.cat(tmp_scores, dim=1)\n",
    "                scores = torch.max(scores, dim=1).values\n",
    "\n",
    "                full_scores.append(scores)\n",
    "                full_labels.append(labels)\n",
    "        \n",
    "        full_labels = torch.cat([label for label in full_labels])\n",
    "        full_scores = torch.cat([score for score in full_scores])\n",
    "        fpr, tpr, _ = roc_curve(full_labels.cpu().detach(), full_scores.cpu().detach(), pos_label=0)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        print(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T13:38:09.826794Z",
     "start_time": "2024-05-19T13:38:08.547048Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_seed(seed = 42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "CONFIG = {\n",
    "    \"seed\": 42,\n",
    "    \"epochs\": 100,\n",
    "    \"num_classes\": 2,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"train_batch_size\": 32,\n",
    "    \"val_batch_size\": 16,\n",
    "    \"test_batch_size\": 128,\n",
    "    \"criterion\": nn.MSELoss(),\n",
    "    \"device\":\n",
    "        torch.device(\n",
    "            \"cuda:0\" if torch.cuda.is_available()\n",
    "            else \"mps\" if torch.backends.mps.is_available()\n",
    "            else \"cpu\"\n",
    "        )\n",
    "}\n",
    "\n",
    "set_seed(CONFIG['seed'])\n",
    "\n",
    "data_path = \"./data/train/\"\n",
    "data_path_test = \"./data/test/\"\n",
    "\n",
    "\n",
    "meta_train_df = pd.read_csv(\"./data/train.csv\")\n",
    "meta_test_df = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "train_df = meta_train_df[['filename', 'is_normal', 'machine_id']]\n",
    "train_dataset = AudioDataset(train_df, data_path,in_memory=True, sgram_type=\"mel\", augment=True, split_sgram=True)\n",
    "test_df = meta_test_df[['filename', 'is_normal', 'machine_id']]\n",
    "test_dataset = AudioDataset(test_df, data_path_test, in_memory=True, sgram_type=\"mel\", test_mode=True)\n",
    "\n",
    "num_items = len(train_dataset)\n",
    "#num_train = int(0.8 * num_items)\n",
    "#num_val = num_items-num_train\n",
    "num_train = 1 * num_items\n",
    "num_val = 0\n",
    "\n",
    "train_ds, val_ds = random_split(train_dataset, [num_train, num_val])\n",
    "test_ds = test_dataset\n",
    "\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=CONFIG['train_batch_size'], shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=CONFIG['val_batch_size'], shuffle=False)\n",
    "test_dl = DataLoader(test_ds, batch_size=CONFIG[\"test_batch_size\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 32, 128])\n"
     ]
    }
   ],
   "source": [
    "inputs, labels = next(iter(train_dl))\n",
    "\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T13:38:10.555964Z",
     "start_time": "2024-05-19T13:38:09.827807Z"
    }
   },
   "outputs": [],
   "source": [
    "input_size = next(iter(train_dl))[0].shape[1] * next(iter(train_dl))[0].shape[2] * next(iter(train_dl))[0].shape[3]\n",
    "model = Autoencoder(input_size, encoding_dim=128)\n",
    "model = model.to(CONFIG[\"device\"])\n",
    "optimizer = optim.Adam(model.parameters(), lr=CONFIG[\"learning_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2370, 1, 32, 128])\n"
     ]
    }
   ],
   "source": [
    "# compute metrics\n",
    "inputs_cat=[]\n",
    "for inputs, labels in train_dl:\n",
    "    inputs_cat.append(inputs)\n",
    "inputs_cat = torch.cat([input for input in inputs_cat])\n",
    "print(inputs_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n"
     ]
    }
   ],
   "source": [
    "# compute the min and max value for each frequency of the batch_sizexchannelxtimexfrequecy\n",
    "min = torch.min(inputs_cat, dim=0).values\n",
    "max = torch.max(inputs_cat, dim=0).values\n",
    "print(max.shape)\n",
    "print(min.shape)\n",
    "train_dataset.min = min\n",
    "train_dataset.max = max\n",
    "test_dataset.min = min\n",
    "test_dataset.max = max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/200], Train loss:  0.0398\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1101, 77]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcriterion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 68\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, original_train_dataset, train_dl, val_dl, test_dl, criterion, optimizer, device, epochs, step_size)\u001b[0m\n\u001b[1;32m     66\u001b[0m full_labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([label \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m full_labels])\n\u001b[1;32m     67\u001b[0m full_scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([score \u001b[38;5;28;01mfor\u001b[39;00m score \u001b[38;5;129;01min\u001b[39;00m full_scores])\n\u001b[0;32m---> 68\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m \u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m roc_auc \u001b[38;5;241m=\u001b[39m auc(fpr, tpr)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(roc_auc)\n",
      "File \u001b[0;32m~/miniconda3/envs/asi/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/asi/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:1094\u001b[0m, in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    993\u001b[0m     {\n\u001b[1;32m    994\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1003\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m ):\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[1;32m   1006\u001b[0m \n\u001b[1;32m   1007\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;124;03m    array([ inf, 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1094\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[1;32m   1106\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/asi/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:805\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[1;32m    803\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[0;32m--> 805\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m y_true \u001b[38;5;241m=\u001b[39m column_or_1d(y_true)\n\u001b[1;32m    807\u001b[0m y_score \u001b[38;5;241m=\u001b[39m column_or_1d(y_score)\n",
      "File \u001b[0;32m~/miniconda3/envs/asi/lib/python3.12/site-packages/sklearn/utils/validation.py:409\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    407\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    412\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1101, 77]"
     ]
    }
   ],
   "source": [
    "training=True\n",
    "if training:\n",
    "    train_model(model, train_dataset, train_dl, val_dl, test_dl, CONFIG[\"criterion\"], optimizer, CONFIG[\"device\"], 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train different AE for each machine_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed = 42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "learning_rate={0:0.001, 2:0.01, 4:0.1}\n",
    "CONFIG = {\n",
    "    \"seed\": 42,\n",
    "    \"epochs\": 20,\n",
    "    \"num_classes\": 2,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"train_batch_size\": 32,\n",
    "    \"val_batch_size\": 16,\n",
    "    \"test_batch_size\": 128,\n",
    "    \"criterion\": nn.MSELoss(),\n",
    "    \"device\":\n",
    "        torch.device(\n",
    "            \"cuda:0\" if torch.cuda.is_available()\n",
    "            else \"mps\" if torch.backends.mps.is_available()\n",
    "            else \"cpu\"\n",
    "        )\n",
    "}\n",
    "\n",
    "set_seed(CONFIG['seed'])\n",
    "\n",
    "data_path = \"./data/train/\"\n",
    "data_path_test = \"./data/test/\"\n",
    "\n",
    "\n",
    "meta_train_df = pd.read_csv(\"./data/train.csv\")\n",
    "meta_test_df = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "train_df = meta_train_df[['filename', 'is_normal', 'machine_id']]\n",
    "\n",
    "train_df_0= train_df[train_df['machine_id'] == 0].reset_index(drop=True)\n",
    "train_dataset_0 = AudioDataset(train_df_0, data_path,in_memory=True, sgram_type=\"mel\")\n",
    "\n",
    "train_df_2= train_df[train_df['machine_id'] == 2].reset_index(drop=True)\n",
    "train_dataset_2 = AudioDataset(train_df_2, data_path,in_memory=True, sgram_type=\"mel\")\n",
    "\n",
    "train_df_4= train_df[train_df['machine_id'] == 4].reset_index(drop=True)\n",
    "train_dataset_4 = AudioDataset(train_df_4, data_path,in_memory=True, sgram_type=\"mel\")\n",
    "\n",
    "test_df = meta_test_df[['filename', 'is_normal', 'machine_id']]\n",
    "\n",
    "test_df_0= test_df[test_df['machine_id'] == 0].reset_index(drop=True)\n",
    "test_dataset_0 = AudioDataset(test_df_0, data_path_test, in_memory=True, sgram_type=\"mel\")\n",
    "\n",
    "test_df_2= test_df[test_df['machine_id'] == 2].reset_index(drop=True)\n",
    "test_dataset_2 = AudioDataset(test_df_2, data_path_test, in_memory=True, sgram_type=\"mel\")\n",
    "\n",
    "test_df_4= test_df[test_df['machine_id'] == 4].reset_index(drop=True)\n",
    "test_dataset_4 = AudioDataset(test_df_4, data_path_test, in_memory=True, sgram_type=\"mel\")\n",
    "\n",
    "num_items = len(train_dataset_0)\n",
    "num_train = int(0.8 * num_items)\n",
    "num_val = num_items-num_train\n",
    "train_ds_0, val_ds_0 = random_split(train_dataset_0, [num_train, num_val])\n",
    "\n",
    "num_items = len(train_dataset_2)\n",
    "num_train = int(0.8 * num_items)\n",
    "num_val = num_items-num_train\n",
    "train_ds_2, val_ds_2 = random_split(train_dataset_2, [num_train, num_val])\n",
    "\n",
    "num_items = len(train_dataset_4)\n",
    "num_train = int(0.8 * num_items)\n",
    "num_val = num_items-num_train\n",
    "train_ds_4, val_ds_4 = random_split(train_dataset_4, [num_train, num_val])\n",
    "\n",
    "test_ds_0 = test_dataset_0\n",
    "test_ds_2 = test_dataset_2\n",
    "test_ds_4 = test_dataset_4\n",
    "\n",
    "train_dl_0 = DataLoader(train_ds_0, batch_size=CONFIG['train_batch_size'], shuffle=True)\n",
    "val_dl_0 = DataLoader(val_ds_0, batch_size=CONFIG['val_batch_size'], shuffle=False)\n",
    "test_dl_0 = DataLoader(test_ds_0, batch_size=CONFIG[\"test_batch_size\"], shuffle=False)\n",
    "\n",
    "train_dl_2 = DataLoader(train_ds_2, batch_size=CONFIG['train_batch_size'], shuffle=True)\n",
    "val_dl_2 = DataLoader(val_ds_2, batch_size=CONFIG['val_batch_size'], shuffle=False)\n",
    "test_dl_2 = DataLoader(test_ds_2, batch_size=CONFIG[\"test_batch_size\"], shuffle=False)\n",
    "\n",
    "train_dl_4 = DataLoader(train_ds_4, batch_size=CONFIG['train_batch_size'], shuffle=True)\n",
    "val_dl_4 = DataLoader(val_ds_4, batch_size=CONFIG['val_batch_size'], shuffle=False)\n",
    "test_dl_4 = DataLoader(test_ds_4, batch_size=CONFIG[\"test_batch_size\"], shuffle=False)\n",
    "\n",
    "# create dict\n",
    "train_dl_dict = {0: train_dl_0, 2: train_dl_2, 4: train_dl_4}\n",
    "val_dl_dict = {0: val_dl_0, 2: val_dl_2, 4: val_dl_4}\n",
    "test_dl_dict = {0: test_dl_0, 2: test_dl_2, 4: test_dl_4}\n",
    "train_dataset_dict={0: train_dataset_0, 2: train_dataset_2, 4: train_dataset_4}\n",
    "test_dataset_dict={0: test_dataset_0, 2: test_dataset_2, 4: test_dataset_4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds_0, val_ds_0, test_ds_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute metrics\n",
    "inputs_cat={}\n",
    "for key in train_dl_dict.keys():\n",
    "    inputs_cat[key]=[]\n",
    "    for inputs, labels in train_dl_dict[key]:\n",
    "        inputs_cat[key].append(inputs)\n",
    "    inputs_cat[key] = torch.cat([input for input in inputs_cat[key]])\n",
    "    print(inputs_cat[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the min and max value for each frequency of the batch_sizexchannelxtimexfrequecy\n",
    "for key in train_dl_dict.keys():\n",
    "    min = torch.min(inputs_cat[key], dim=0).values\n",
    "    max = torch.max(inputs_cat[key], dim=0).values\n",
    "    print(max.shape)\n",
    "    print(min.shape)\n",
    "    train_dataset_dict[key].min = min\n",
    "    train_dataset_dict[key].max = max\n",
    "    test_dataset_dict[key].min = min\n",
    "    test_dataset_dict[key].max = max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training=True\n",
    "models_dict={}\n",
    "if training:\n",
    "    for key in train_dl_dict.keys():\n",
    "        input_size = next(iter(train_dl_dict[key]))[0].shape[1] * next(iter(train_dl_dict[key]))[0].shape[2] * next(iter(train_dl_dict[key]))[0].shape[3]\n",
    "        model = Autoencoder(input_size, encoding_dim=128)\n",
    "        model = model.to(CONFIG[\"device\"])\n",
    "        optimizer = optim.Adam(model.parameters(), lr=CONFIG[\"learning_rate\"][key])\n",
    "        train_model(model, train_dl_dict[key], val_dl_dict[key], test_dl_dict[key], CONFIG[\"criterion\"], optimizer, CONFIG[\"device\"], CONFIG[\"epochs\"],10)\n",
    "        models_dict[key]=model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
