{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-18T12:31:13.200454Z",
     "start_time": "2024-05-18T12:31:10.904360Z"
    }
   },
   "source": [
    "%reset -f\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "\n",
    "from customDatasets.audioDataset import AudioDataset\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:31:13.265368Z",
     "start_time": "2024-05-18T12:31:13.201846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# free gpu\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ],
   "id": "c68a8648b625fdcc",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:31:13.285997Z",
     "start_time": "2024-05-18T12:31:13.266732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def set_seed(seed = 42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "CONFIG = {\n",
    "    \"seed\": 42,\n",
    "    \"epochs\": 20,\n",
    "    \"num_classes\": 2,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"train_batch_size\": 32,\n",
    "    \"val_batch_size\": 16,\n",
    "    \"test_batch_size\": 128,\n",
    "    \"criterion\": nn.MSELoss(),\n",
    "    \"device\":\n",
    "        torch.device(\n",
    "            \"cuda:0\" if torch.cuda.is_available()\n",
    "            else \"mps\" if torch.backends.mps.is_available()\n",
    "            else \"cpu\"\n",
    "        )\n",
    "}\n",
    "\n",
    "set_seed(CONFIG['seed'])\n",
    "\n",
    "data_path = \"./data/train/\"\n",
    "data_path_test = \"./data/test/\"\n",
    "\n",
    "\n",
    "meta_train_df = pd.read_csv(\"./data/train.csv\")\n",
    "meta_test_df = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "train_df = meta_train_df[['filename', 'is_normal', 'machine_id']]\n",
    "train_dataset = AudioDataset(train_df, data_path)\n",
    "test_df = meta_test_df[['filename', 'is_normal', 'machine_id']]\n",
    "test_dataset = AudioDataset(test_df, data_path_test)\n",
    "\n",
    "num_items = len(train_dataset)\n",
    "num_train = int(0.8 * num_items)\n",
    "num_val = num_items-num_train\n",
    "\n",
    "train_ds, val_ds = random_split(train_dataset, [num_train, num_val])\n",
    "test_ds = test_dataset\n",
    "\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=CONFIG['train_batch_size'], shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=CONFIG['val_batch_size'], shuffle=False)\n",
    "test_dl = DataLoader(test_ds, batch_size=CONFIG[\"test_batch_size\"], shuffle=False)"
   ],
   "id": "98fa48963b6097df",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:31:23.188319Z",
     "start_time": "2024-05-18T12:31:13.287570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# compute metrics\n",
    "inputs_cat=[]\n",
    "for inputs, labels in train_dl:\n",
    "    inputs_cat.append(inputs)\n",
    "inputs_cat = torch.cat([input for input in inputs_cat])\n",
    "print(inputs_cat.shape)\n",
    "val_cat=[]\n",
    "for inputs, labels in val_dl:\n",
    "    val_cat.append(inputs)\n",
    "val_cat = torch.cat([input for input in val_cat])\n",
    "print(val_cat.shape)\n",
    "test_cat=[]\n",
    "for inputs, labels in test_dl:\n",
    "    test_cat.append(inputs)\n",
    "test_cat = torch.cat([input for input in test_cat])\n",
    "print(test_cat.shape)"
   ],
   "id": "8e79c96ed388d33a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1896, 1, 320, 128])\n",
      "torch.Size([474, 1, 320, 128])\n",
      "torch.Size([1101, 1, 320, 128])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:31:23.194145Z",
     "start_time": "2024-05-18T12:31:23.189588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# flatten it\n",
    "inputs_cat = inputs_cat.view(inputs_cat.shape[0], -1)\n",
    "val_cat = val_cat.view(val_cat.shape[0], -1)\n",
    "test_cat = test_cat.view(test_cat.shape[0], -1)\n",
    "print(inputs_cat.shape)\n",
    "print(val_cat.shape)\n",
    "print(test_cat.shape)"
   ],
   "id": "5e3bd5eb03147743",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1896, 40960])\n",
      "torch.Size([474, 40960])\n",
      "torch.Size([1101, 40960])\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:34:02.677253Z",
     "start_time": "2024-05-18T12:33:01.419810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "values=[]\n",
    "for n_components, n_clusters in [(5,2),(5,3),(5,4),(10,2),(10,3),(10,4),(15,2),(15,3),(15,4),(20,2),(20,3),(20,4)]:\n",
    "    # do pca\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(inputs_cat)\n",
    "    inputs_pca = pca.transform(inputs_cat)\n",
    "    val_pca = pca.transform(val_cat)\n",
    "    test_pca = pca.transform(test_cat)\n",
    "    print(inputs_pca.shape)\n",
    "    \n",
    "    # use a clustering method hierarchical\n",
    "    from sklearn.cluster import AgglomerativeClustering\n",
    "    clustering = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "    clustering.fit(inputs_pca)\n",
    "    \n",
    "    # Calculate centroids\n",
    "    centroids = []\n",
    "    for cluster_label in range(n_clusters):\n",
    "        cluster_points = inputs_pca[clustering.labels_ == cluster_label]\n",
    "        centroid = cluster_points.mean(axis=0)\n",
    "        centroids.append(centroid)\n",
    "    centroids = np.array(centroids)\n",
    "    \n",
    "    # Calculate distances to centroids\n",
    "    distances_to_centroids = euclidean_distances(test_pca, centroids)\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(test_df['is_normal'], distances_to_centroids[:, 0])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f\"n_components: {n_components}, n_clusters: {n_clusters}, auc: {roc_auc}\")\n",
    "    values.append((n_components, n_clusters, roc_auc))\n",
    "\n",
    "best=values[np.argmax([v[2] for v in values])]\n",
    "print(f\"best: {best}\")"
   ],
   "id": "e773e50174a98e86",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1896, 5)\n",
      "n_components: 5, n_clusters: 2, auc: 0.2721223470661673\n",
      "(1896, 5)\n",
      "n_components: 5, n_clusters: 3, auc: 0.5882313774448605\n",
      "(1896, 5)\n",
      "n_components: 5, n_clusters: 4, auc: 0.517191011235955\n",
      "(1896, 10)\n",
      "n_components: 10, n_clusters: 2, auc: 0.27590928006658344\n",
      "(1896, 10)\n",
      "n_components: 10, n_clusters: 3, auc: 0.5762380357885977\n",
      "(1896, 10)\n",
      "n_components: 10, n_clusters: 4, auc: 0.492267998335414\n",
      "(1896, 15)\n",
      "n_components: 15, n_clusters: 2, auc: 0.2580982105701207\n",
      "(1896, 15)\n",
      "n_components: 15, n_clusters: 3, auc: 0.5906367041198503\n",
      "(1896, 15)\n",
      "n_components: 15, n_clusters: 4, auc: 0.4990470245526425\n",
      "(1896, 20)\n",
      "n_components: 20, n_clusters: 2, auc: 0.2757761131918436\n",
      "(1896, 20)\n",
      "n_components: 20, n_clusters: 3, auc: 0.5785892634207241\n",
      "(1896, 20)\n",
      "n_components: 20, n_clusters: 4, auc: 0.48675405742821476\n",
      "best: (15, 3, 0.5906367041198503)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:34:26.070398Z",
     "start_time": "2024-05-18T12:34:02.678902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# using the LOF\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "for n_components in [2,5,10,15,20]:\n",
    "    # do pca\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(inputs_cat)\n",
    "    inputs_pca = pca.transform(inputs_cat)\n",
    "    val_pca = pca.transform(val_cat)\n",
    "    test_pca = pca.transform(test_cat)\n",
    "    print(inputs_pca.shape)\n",
    "    \n",
    "    # use a clustering method hierarchical\n",
    "    clf = LocalOutlierFactor(novelty=True)\n",
    "    clf.fit(inputs_pca)\n",
    "    \n",
    "    # Calculate distances to centroids\n",
    "    distances_to_centroids = clf.decision_function(test_pca)\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(test_df['is_normal'], distances_to_centroids)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f\"n_components: {n_components}, auc: {roc_auc}\")"
   ],
   "id": "94c91fb937663d37",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1896, 2)\n",
      "n_components: 2, auc: 0.5933104452767374\n",
      "(1896, 5)\n",
      "n_components: 5, auc: 0.6353225135247609\n",
      "(1896, 10)\n",
      "n_components: 10, auc: 0.6130711610486892\n",
      "(1896, 15)\n",
      "n_components: 15, auc: 0.5766708281315024\n",
      "(1896, 20)\n",
      "n_components: 20, auc: 0.5984519350811486\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T12:33:01.417396Z",
     "start_time": "2024-05-18T12:33:01.413872Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9e5e43522713242f",
   "outputs": [],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
