{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-18T07:29:02.760838Z",
     "start_time": "2024-05-18T07:29:02.510951Z"
    }
   },
   "source": [
    "%reset -f\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "\n",
    "from customDatasets.audioDataset import AudioDataset\n"
   ],
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T07:29:02.768262Z",
     "start_time": "2024-05-18T07:29:02.762082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# free gpu\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ],
   "id": "f968c3c21dc371bb",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T07:29:02.778474Z",
     "start_time": "2024-05-18T07:29:02.769897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ConvolutionalAE(nn.Module):\n",
    "    def __init__(self, encoding_dim):\n",
    "        super(ConvolutionalAE, self).__init__()\n",
    "        self.encoding_dim = encoding_dim\n",
    "        self.encoder = nn.Sequential(\n",
    "            # (320, 128)\n",
    "            nn.Conv2d(1, 32, kernel_size=5, stride=(1,2), padding=(2,2)),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            # (320, 64)\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=(1,2), padding=(2,2)),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            # (320, 32)\n",
    "            nn.Conv2d(64, 128, kernel_size=5, stride=(2,2), padding=(2,2)),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            # (160, 16)\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=(2,2), padding=(1,1)),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            # (80, 8)\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=(2,2), padding=(1,1)),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            # (40, 4, 512)\n",
    "        )\n",
    "               \n",
    "        # inflates the latent space to the shape of the last layer of the encoder\n",
    "        self.fc=nn.Sequential(\n",
    "            nn.Linear(512*40*4, self.encoding_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.encoding_dim, 512*40*4),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.decoder=nn.Sequential(\n",
    "            # (512, 40, 4)\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=3, stride=(2,2), padding=(1,1),output_padding=(1,1)),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            # (256, 80, 8)\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=(2,2), padding=(1,1),output_padding=(1,1)),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            # (128, 160, 16)\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=(2,2), padding=(1,1),output_padding=(1,1)),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            # (64, 320, 32)\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=5, stride=(1,2), padding=(2,2),output_padding=(0,1)),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            # (32, 320, 64)\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=5, stride=(1,2), padding=(2,2),output_padding=(0,1)),\n",
    "            # (1, 320, 128)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        encoded = encoded.view(-1, 512*40*4)\n",
    "        x=self.fc(encoded)\n",
    "        x = x.view(-1, 512, 40, 4)\n",
    "        decoded = self.decoder(x)\n",
    "        \n",
    "        return decoded"
   ],
   "id": "86b9d0ccc25a1707",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T07:29:02.788192Z",
     "start_time": "2024-05-18T07:29:02.780558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model, train_dl, val_dl, test_dl, criterion, optimizer, device, epochs=5, step_size=5):\n",
    "    lr_scheduler=torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=0.1)\n",
    "    for epoch in range(epochs):\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "\n",
    "        for inputs, labels in train_dl:\n",
    "            model.train()\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, inputs)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "        lr_scheduler.step()\n",
    "        print(f'Epoch[{epoch + 1}/{epochs}], Train loss: {np.average(train_losses): .4f}')\n",
    "        \n",
    "        \n",
    "        for inputs, labels in val_dl:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, inputs)\n",
    "                val_losses.append(loss.item())\n",
    "        print(f'Epoch[{epoch + 1}/{epochs}], Val loss: {np.average(val_losses): .4f}')\n",
    " \n",
    "        scores = []\n",
    "        full_labels = []\n",
    "        for inputs, labels in test_dl:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                mse = torch.sum((outputs-inputs)**2,dim=(1,2,3))/(inputs.shape[1]*inputs.shape[2]*inputs.shape[3])            \n",
    "                scores.append(mse)\n",
    "                full_labels.append(labels)\n",
    "        \n",
    "        full_labels = torch.cat([label for label in full_labels])\n",
    "        scores = torch.cat([score for score in scores])\n",
    "        fpr, tpr, _ = roc_curve(full_labels.cpu().detach(), scores.cpu().detach(), pos_label=0)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        print(roc_auc)\n",
    "        \n",
    "    return np.average(train_losses),np.average(val_losses),roc_auc"
   ],
   "id": "f56f0745d3302d87",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T07:29:02.801914Z",
     "start_time": "2024-05-18T07:29:02.789416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def set_seed(seed = 42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "CONFIG = {\n",
    "    \"seed\": 42,\n",
    "    \"epochs\": 10,\n",
    "    \"num_classes\": 2,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"train_batch_size\": 32,\n",
    "    \"val_batch_size\": 16,\n",
    "    \"test_batch_size\": 128,\n",
    "    \"criterion\": nn.MSELoss(),\n",
    "    \"device\":\n",
    "        torch.device(\n",
    "            \"cuda:0\" if torch.cuda.is_available()\n",
    "            else \"mps\" if torch.backends.mps.is_available()\n",
    "            else \"cpu\"\n",
    "        )\n",
    "}\n",
    "\n",
    "set_seed(CONFIG['seed'])\n",
    "\n",
    "data_path = \"./data/train/\"\n",
    "data_path_test = \"./data/test/\"\n",
    "\n",
    "\n",
    "meta_train_df = pd.read_csv(\"./data/train.csv\")\n",
    "meta_test_df = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "train_df = meta_train_df[['filename', 'is_normal', 'machine_id']]\n",
    "train_dataset = AudioDataset(train_df, data_path)\n",
    "test_df = meta_test_df[['filename', 'is_normal', 'machine_id']]\n",
    "test_dataset = AudioDataset(test_df, data_path_test)\n",
    "\n",
    "num_items = len(train_dataset)\n",
    "num_train = int(0.8 * num_items)\n",
    "num_val = num_items-num_train\n",
    "\n",
    "train_ds, val_ds = random_split(train_dataset, [num_train, num_val])\n",
    "test_ds = test_dataset\n",
    "\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=CONFIG['train_batch_size'], shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=CONFIG['val_batch_size'], shuffle=False)\n",
    "test_dl = DataLoader(test_ds, batch_size=CONFIG[\"test_batch_size\"], shuffle=True)"
   ],
   "id": "36ce87d24bd72ad5",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T07:29:03.093705Z",
     "start_time": "2024-05-18T07:29:02.803179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = ConvolutionalAE(encoding_dim=128)\n",
    "model = model.to(CONFIG[\"device\"])\n",
    "optimizer = optim.Adam(model.parameters(), lr=CONFIG[\"learning_rate\"])\n",
    "for batch in train_dl:\n",
    "    inputs, labels = batch\n",
    "    print(inputs.shape)\n",
    "    inputs = inputs.to(CONFIG[\"device\"])\n",
    "    outputs = model(inputs)\n",
    "    print(outputs.shape)\n",
    "    break"
   ],
   "id": "8b01c9d83af18dc7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 320, 128])\n",
      "torch.Size([32, 1, 320, 128])\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T07:29:10.953062Z",
     "start_time": "2024-05-18T07:29:03.094895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# compute metrics\n",
    "inputs_cat=[]\n",
    "for inputs, labels in train_dl:\n",
    "    inputs_cat.append(inputs)\n",
    "inputs_cat = torch.cat([input for input in inputs_cat])\n",
    "print(inputs_cat.shape)"
   ],
   "id": "ed6681960638cdc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1896, 1, 320, 128])\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T07:29:11.167609Z",
     "start_time": "2024-05-18T07:29:10.954258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# compute the min and max value for each frequency of the batch_sizexchannelxtimexfrequecy\n",
    "min = torch.min(inputs_cat, dim=0).values\n",
    "max = torch.max(inputs_cat, dim=0).values\n",
    "print(max.shape)\n",
    "print(min.shape)\n",
    "train_dataset.min = min\n",
    "train_dataset.max = max\n",
    "test_dataset.min = min\n",
    "test_dataset.max = max\n",
    "measures = []"
   ],
   "id": "612f0834c93b8867",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 320, 128])\n",
      "torch.Size([1, 320, 128])\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T07:48:56.573650Z",
     "start_time": "2024-05-18T07:29:11.168651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training=True\n",
    "\n",
    "# testing emb space size\n",
    "if training:\n",
    "    for emb_space_size in [32, 64, 128, 256, 512]:\n",
    "        model = ConvolutionalAE(encoding_dim=emb_space_size)\n",
    "        model = model.to(CONFIG[\"device\"])\n",
    "        optimizer = optim.Adam(model.parameters(), lr=CONFIG[\"learning_rate\"])\n",
    "        measures.append(train_model(model, train_dl, val_dl, test_dl, CONFIG[\"criterion\"], optimizer, CONFIG[\"device\"], CONFIG[\"epochs\"]))\n",
    "    for emb_space_size, measure in zip([32, 64, 128, 256, 512], measures):\n",
    "        print(f\"Emb space size: {emb_space_size}, Train loss: {measure[0]}, Val loss: {measure[1]}, ROC AUC: {measure[2]}\")"
   ],
   "id": "9a992a409c40866e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/10], Train loss:  0.6116\n",
      "Epoch[1/10], Val loss:  0.0290\n",
      "0.7491427382438619\n",
      "Epoch[2/10], Train loss:  0.0292\n",
      "Epoch[2/10], Val loss:  0.0289\n",
      "0.6680482729920931\n",
      "Epoch[3/10], Train loss:  0.0255\n",
      "Epoch[3/10], Val loss:  0.0250\n",
      "0.7231710362047441\n",
      "Epoch[4/10], Train loss:  0.0243\n",
      "Epoch[4/10], Val loss:  0.0242\n",
      "0.7303662089055347\n",
      "Epoch[5/10], Train loss:  0.0236\n",
      "Epoch[5/10], Val loss:  0.0240\n",
      "0.7391593841032044\n",
      "Epoch[6/10], Train loss:  0.0235\n",
      "Epoch[6/10], Val loss:  0.0240\n",
      "0.7411652101539743\n",
      "Epoch[7/10], Train loss:  0.0234\n",
      "Epoch[7/10], Val loss:  0.0239\n",
      "0.7405493133583022\n",
      "Epoch[8/10], Train loss:  0.0234\n",
      "Epoch[8/10], Val loss:  0.0240\n",
      "0.7454140657511444\n",
      "Epoch[9/10], Train loss:  0.0234\n",
      "Epoch[9/10], Val loss:  0.0240\n",
      "0.7421098626716605\n",
      "Epoch[10/10], Train loss:  0.0234\n",
      "Epoch[10/10], Val loss:  0.0240\n",
      "0.7313607990012485\n",
      "Epoch[1/10], Train loss:  0.3134\n",
      "Epoch[1/10], Val loss:  0.0338\n",
      "0.565364128173117\n",
      "Epoch[2/10], Train loss:  0.0334\n",
      "Epoch[2/10], Val loss:  0.0266\n",
      "0.6946025801081981\n",
      "Epoch[3/10], Train loss:  0.0252\n",
      "Epoch[3/10], Val loss:  0.0253\n",
      "0.7336204744069913\n",
      "Epoch[4/10], Train loss:  0.0242\n",
      "Epoch[4/10], Val loss:  0.0256\n",
      "0.7047107781939242\n",
      "Epoch[5/10], Train loss:  0.0236\n",
      "Epoch[5/10], Val loss:  0.0247\n",
      "0.7388389513108613\n",
      "Epoch[6/10], Train loss:  0.0234\n",
      "Epoch[6/10], Val loss:  0.0242\n",
      "0.7105076987099459\n",
      "Epoch[7/10], Train loss:  0.0234\n",
      "Epoch[7/10], Val loss:  0.0248\n",
      "0.7150520183104452\n",
      "Epoch[8/10], Train loss:  0.0231\n",
      "Epoch[8/10], Val loss:  0.0240\n",
      "0.7218934665002081\n",
      "Epoch[9/10], Train loss:  0.0234\n",
      "Epoch[9/10], Val loss:  0.0252\n",
      "0.72367873491469\n",
      "Epoch[10/10], Train loss:  0.0233\n",
      "Epoch[10/10], Val loss:  0.0241\n",
      "0.7300166458593425\n",
      "Epoch[1/10], Train loss:  0.6617\n",
      "Epoch[1/10], Val loss:  0.0320\n",
      "0.6296129837702871\n",
      "Epoch[2/10], Train loss:  0.0281\n",
      "Epoch[2/10], Val loss:  0.0263\n",
      "0.7099958385351645\n",
      "Epoch[3/10], Train loss:  0.0254\n",
      "Epoch[3/10], Val loss:  0.0252\n",
      "0.6926133999167707\n",
      "Epoch[4/10], Train loss:  0.0246\n",
      "Epoch[4/10], Val loss:  0.0249\n",
      "0.6859342488555972\n",
      "Epoch[5/10], Train loss:  0.0239\n",
      "Epoch[5/10], Val loss:  0.0243\n",
      "0.7269080316271328\n",
      "Epoch[6/10], Train loss:  0.0235\n",
      "Epoch[6/10], Val loss:  0.0243\n",
      "0.7168705784436121\n",
      "Epoch[7/10], Train loss:  0.0233\n",
      "Epoch[7/10], Val loss:  0.0245\n",
      "0.7186683312526009\n",
      "Epoch[8/10], Train loss:  0.0234\n",
      "Epoch[8/10], Val loss:  0.0244\n",
      "0.7329671244277987\n",
      "Epoch[9/10], Train loss:  0.0235\n",
      "Epoch[9/10], Val loss:  0.0245\n",
      "0.7138451935081148\n",
      "Epoch[10/10], Train loss:  0.0232\n",
      "Epoch[10/10], Val loss:  0.0241\n",
      "0.7196379525593009\n",
      "Epoch[1/10], Train loss:  0.6189\n",
      "Epoch[1/10], Val loss:  0.0472\n",
      "0.7164710778193923\n",
      "Epoch[2/10], Train loss:  0.0354\n",
      "Epoch[2/10], Val loss:  0.0306\n",
      "0.6761756138160633\n",
      "Epoch[3/10], Train loss:  0.0291\n",
      "Epoch[3/10], Val loss:  0.0273\n",
      "0.6982147315855182\n",
      "Epoch[4/10], Train loss:  0.0268\n",
      "Epoch[4/10], Val loss:  0.0266\n",
      "0.6985393258426966\n",
      "Epoch[5/10], Train loss:  0.0256\n",
      "Epoch[5/10], Val loss:  0.0253\n",
      "0.7036246358718269\n",
      "Epoch[6/10], Train loss:  0.0248\n",
      "Epoch[6/10], Val loss:  0.0251\n",
      "0.7083208489388265\n",
      "Epoch[7/10], Train loss:  0.0246\n",
      "Epoch[7/10], Val loss:  0.0251\n",
      "0.7160965459841865\n",
      "Epoch[8/10], Train loss:  0.0245\n",
      "Epoch[8/10], Val loss:  0.0245\n",
      "0.7213025384935497\n",
      "Epoch[9/10], Train loss:  0.0244\n",
      "Epoch[9/10], Val loss:  0.0246\n",
      "0.7191677070328757\n",
      "Epoch[10/10], Train loss:  0.0244\n",
      "Epoch[10/10], Val loss:  0.0249\n",
      "0.7192717436537661\n",
      "Epoch[1/10], Train loss:  0.5466\n",
      "Epoch[1/10], Val loss:  0.0418\n",
      "0.5204910528506034\n",
      "Epoch[2/10], Train loss:  0.0373\n",
      "Epoch[2/10], Val loss:  0.0337\n",
      "0.6816437786100707\n",
      "Epoch[3/10], Train loss:  0.0301\n",
      "Epoch[3/10], Val loss:  0.0293\n",
      "0.6972867249271744\n",
      "Epoch[4/10], Train loss:  0.0282\n",
      "Epoch[4/10], Val loss:  0.0288\n",
      "0.7181190178942989\n",
      "Epoch[5/10], Train loss:  0.0273\n",
      "Epoch[5/10], Val loss:  0.0269\n",
      "0.7129837702871411\n",
      "Epoch[6/10], Train loss:  0.0259\n",
      "Epoch[6/10], Val loss:  0.0263\n",
      "0.7058218893050354\n",
      "Epoch[7/10], Train loss:  0.0255\n",
      "Epoch[7/10], Val loss:  0.0265\n",
      "0.71535164377861\n",
      "Epoch[8/10], Train loss:  0.0257\n",
      "Epoch[8/10], Val loss:  0.0275\n",
      "0.7121972534332085\n",
      "Epoch[9/10], Train loss:  0.0253\n",
      "Epoch[9/10], Val loss:  0.0260\n",
      "0.7198709945900956\n",
      "Epoch[10/10], Train loss:  0.0252\n",
      "Epoch[10/10], Val loss:  0.0262\n",
      "0.7085892634207241\n",
      "Emb space size: 32, Train loss: 0.02343009104952216, Val loss: 0.023966445960104464, ROC AUC: 0.7313607990012485\n",
      "Emb space size: 64, Train loss: 0.023298380927493176, Val loss: 0.024125935633977254, ROC AUC: 0.7300166458593425\n",
      "Emb space size: 128, Train loss: 0.02321693968648712, Val loss: 0.024117170087993144, ROC AUC: 0.7196379525593009\n",
      "Emb space size: 256, Train loss: 0.024374781797329586, Val loss: 0.024861768633127213, ROC AUC: 0.7192717436537661\n",
      "Emb space size: 512, Train loss: 0.025223139952868224, Val loss: 0.026171704257527986, ROC AUC: 0.7085892634207241\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T07:48:56.625428Z",
     "start_time": "2024-05-18T07:48:56.575948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# take the best one and train it for more epochs\n",
    "if training:\n",
    "    emb_space_measures=[32, 64, 128, 256, 512]\n",
    "    model = ConvolutionalAE(encoding_dim=emb_space_measures[np.argmax([measure[2] for measure in measures])])\n",
    "    model = model.to(CONFIG[\"device\"])"
   ],
   "id": "b7de0bec6b2f58e8",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:08:10.105251Z",
     "start_time": "2024-05-18T07:48:56.626517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if training:\n",
    "    optimizer = optim.Adam(model.parameters(), lr=+0.01)\n",
    "    train_model(model, train_dl, val_dl, test_dl, CONFIG[\"criterion\"], optimizer, CONFIG[\"device\"], 50, 20)"
   ],
   "id": "acae56582dfab61b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/50], Train loss:  0.6693\n",
      "Epoch[1/50], Val loss:  0.0452\n",
      "0.7473366625052018\n",
      "Epoch[2/50], Train loss:  0.0291\n",
      "Epoch[2/50], Val loss:  0.0268\n",
      "0.663866000832293\n",
      "Epoch[3/50], Train loss:  0.0270\n",
      "Epoch[3/50], Val loss:  0.0278\n",
      "0.7280316271327507\n",
      "Epoch[4/50], Train loss:  0.0254\n",
      "Epoch[4/50], Val loss:  0.0264\n",
      "0.7251560549313358\n",
      "Epoch[5/50], Train loss:  0.0248\n",
      "Epoch[5/50], Val loss:  0.0241\n",
      "0.6803537245110278\n",
      "Epoch[6/50], Train loss:  0.0240\n",
      "Epoch[6/50], Val loss:  0.0241\n",
      "0.7525301706200582\n",
      "Epoch[7/50], Train loss:  0.0238\n",
      "Epoch[7/50], Val loss:  0.0238\n",
      "0.7207199334165627\n",
      "Epoch[8/50], Train loss:  0.0233\n",
      "Epoch[8/50], Val loss:  0.0237\n",
      "0.7310944652517687\n",
      "Epoch[9/50], Train loss:  0.0229\n",
      "Epoch[9/50], Val loss:  0.0240\n",
      "0.7332417811069497\n",
      "Epoch[10/50], Train loss:  0.0229\n",
      "Epoch[10/50], Val loss:  0.0232\n",
      "0.7316229712858927\n",
      "Epoch[11/50], Train loss:  0.0228\n",
      "Epoch[11/50], Val loss:  0.0233\n",
      "0.7249438202247191\n",
      "Epoch[12/50], Train loss:  0.0228\n",
      "Epoch[12/50], Val loss:  0.0230\n",
      "0.6936870578443612\n",
      "Epoch[13/50], Train loss:  0.0223\n",
      "Epoch[13/50], Val loss:  0.0223\n",
      "0.7319725343320849\n",
      "Epoch[14/50], Train loss:  0.0222\n",
      "Epoch[14/50], Val loss:  0.0225\n",
      "0.7376029962546816\n",
      "Epoch[15/50], Train loss:  0.0221\n",
      "Epoch[15/50], Val loss:  0.0225\n",
      "0.7032667498959634\n",
      "Epoch[16/50], Train loss:  0.0220\n",
      "Epoch[16/50], Val loss:  0.0224\n",
      "0.6993466500208073\n",
      "Epoch[17/50], Train loss:  0.0220\n",
      "Epoch[17/50], Val loss:  0.0228\n",
      "0.69270911360799\n",
      "Epoch[18/50], Train loss:  0.0218\n",
      "Epoch[18/50], Val loss:  0.0225\n",
      "0.711905950894715\n",
      "Epoch[19/50], Train loss:  0.0221\n",
      "Epoch[19/50], Val loss:  0.0222\n",
      "0.6812817311693716\n",
      "Epoch[20/50], Train loss:  0.0218\n",
      "Epoch[20/50], Val loss:  0.0237\n",
      "0.6926175613816064\n",
      "Epoch[21/50], Train loss:  0.0216\n",
      "Epoch[21/50], Val loss:  0.0217\n",
      "0.7385892634207241\n",
      "Epoch[22/50], Train loss:  0.0216\n",
      "Epoch[22/50], Val loss:  0.0219\n",
      "0.7387806908031627\n",
      "Epoch[23/50], Train loss:  0.0215\n",
      "Epoch[23/50], Val loss:  0.0216\n",
      "0.7478069080316272\n",
      "Epoch[24/50], Train loss:  0.0215\n",
      "Epoch[24/50], Val loss:  0.0216\n",
      "0.7520848938826468\n",
      "Epoch[25/50], Train loss:  0.0215\n",
      "Epoch[25/50], Val loss:  0.0218\n",
      "0.7462796504369538\n",
      "Epoch[26/50], Train loss:  0.0215\n",
      "Epoch[26/50], Val loss:  0.0218\n",
      "0.7386246358718268\n",
      "Epoch[27/50], Train loss:  0.0216\n",
      "Epoch[27/50], Val loss:  0.0216\n",
      "0.7489429879317521\n",
      "Epoch[28/50], Train loss:  0.0216\n",
      "Epoch[28/50], Val loss:  0.0218\n",
      "0.7378568456096546\n",
      "Epoch[29/50], Train loss:  0.0215\n",
      "Epoch[29/50], Val loss:  0.0217\n",
      "0.7355472326258843\n",
      "Epoch[30/50], Train loss:  0.0216\n",
      "Epoch[30/50], Val loss:  0.0217\n",
      "0.7435497295047857\n",
      "Epoch[31/50], Train loss:  0.0216\n",
      "Epoch[31/50], Val loss:  0.0217\n",
      "0.7471535580524343\n",
      "Epoch[32/50], Train loss:  0.0214\n",
      "Epoch[32/50], Val loss:  0.0218\n",
      "0.7556387848522681\n",
      "Epoch[33/50], Train loss:  0.0215\n",
      "Epoch[33/50], Val loss:  0.0217\n",
      "0.7551019558884727\n",
      "Epoch[34/50], Train loss:  0.0215\n",
      "Epoch[34/50], Val loss:  0.0218\n",
      "0.7469080316271328\n",
      "Epoch[35/50], Train loss:  0.0215\n",
      "Epoch[35/50], Val loss:  0.0218\n",
      "0.749042863087807\n",
      "Epoch[36/50], Train loss:  0.0214\n",
      "Epoch[36/50], Val loss:  0.0217\n",
      "0.7542779858510196\n",
      "Epoch[37/50], Train loss:  0.0214\n",
      "Epoch[37/50], Val loss:  0.0217\n",
      "0.7415106117353308\n",
      "Epoch[38/50], Train loss:  0.0215\n",
      "Epoch[38/50], Val loss:  0.0216\n",
      "0.7539284228048273\n",
      "Epoch[39/50], Train loss:  0.0213\n",
      "Epoch[39/50], Val loss:  0.0217\n",
      "0.732334581772784\n",
      "Epoch[40/50], Train loss:  0.0214\n",
      "Epoch[40/50], Val loss:  0.0216\n",
      "0.7525509779442363\n",
      "Epoch[41/50], Train loss:  0.0215\n",
      "Epoch[41/50], Val loss:  0.0215\n",
      "0.7408322929671243\n",
      "Epoch[42/50], Train loss:  0.0213\n",
      "Epoch[42/50], Val loss:  0.0216\n",
      "0.7528922180607573\n",
      "Epoch[43/50], Train loss:  0.0214\n",
      "Epoch[43/50], Val loss:  0.0216\n",
      "0.7447107781939243\n",
      "Epoch[44/50], Train loss:  0.0215\n",
      "Epoch[44/50], Val loss:  0.0215\n",
      "0.742488555971702\n",
      "Epoch[45/50], Train loss:  0.0215\n",
      "Epoch[45/50], Val loss:  0.0216\n",
      "0.746287973366625\n",
      "Epoch[46/50], Train loss:  0.0214\n",
      "Epoch[46/50], Val loss:  0.0217\n",
      "0.7473158551810237\n",
      "Epoch[47/50], Train loss:  0.0213\n",
      "Epoch[47/50], Val loss:  0.0217\n",
      "0.7443362463587183\n",
      "Epoch[48/50], Train loss:  0.0213\n",
      "Epoch[48/50], Val loss:  0.0216\n",
      "0.7602122347066168\n",
      "Epoch[49/50], Train loss:  0.0214\n",
      "Epoch[49/50], Val loss:  0.0216\n",
      "0.7548189762796504\n",
      "Epoch[50/50], Train loss:  0.0213\n",
      "Epoch[50/50], Val loss:  0.0215\n",
      "0.7531751976695796\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:08:10.339423Z",
     "start_time": "2024-05-18T08:08:10.106650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#save weights into weights/weights.pth\n",
    "if training:\n",
    "    torch.save(model.state_dict(), \"./weights/weights.pth\")"
   ],
   "id": "f76b4ff33a02e258",
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:08:10.417818Z",
     "start_time": "2024-05-18T08:08:10.340482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_index=np.argmax([measure[2] for measure in measures]) if training else 1\n",
    "model=ConvolutionalAE(encoding_dim=[32, 64, 128, 256, 512][best_index])\n",
    "model.load_state_dict(torch.load(\"./weights/weights.pth\"))\n",
    "model=model.to(CONFIG[\"device\"])\n",
    "train_dataset.with_id=True\n",
    "test_dataset.with_filename=True"
   ],
   "id": "26d868498eb9ddfc",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:08:12.598980Z",
     "start_time": "2024-05-18T08:08:10.418808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# compute the average mse for each id in the val_dl\n",
    "mse_dict = {}\n",
    "for inputs, labels, ids in val_dl:\n",
    "    inputs, labels = inputs.to(CONFIG[\"device\"]), labels.to(CONFIG[\"device\"])\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        diff=outputs-inputs\n",
    "        for id,diff in zip(ids,diff):\n",
    "            if id in mse_dict:\n",
    "                mse_dict[id.item()].append((torch.sum(diff**2)/(inputs.shape[1]*inputs.shape[2]*inputs.shape[3])).item())\n",
    "            else:\n",
    "                mse_dict[id.item()]=[(torch.sum(diff**2)/(inputs.shape[1]*inputs.shape[2]*inputs.shape[3])).item()]\n",
    "\n",
    "print({key:np.average(value) for key,value in mse_dict.items()})"
   ],
   "id": "2d235d6477c4fd0b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.02267526462674141, 4: 0.020125363022089005, 2: 0.018952330574393272}\n"
     ]
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:08:13.294194Z",
     "start_time": "2024-05-18T08:08:12.600241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for inputs, labels, ids in test_dl:\n",
    "    inputs, labels = inputs.to(CONFIG[\"device\"]), labels.to(CONFIG[\"device\"])\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        mse = torch.sum((outputs-inputs)**2,dim=(1,2,3))/(inputs.shape[1]*inputs.shape[2]*inputs.shape[3])\n",
    "        for name,mse in zip(ids,mse):\n",
    "            print(name,mse)\n",
    "        break"
   ],
   "id": "e6eeb8ffa5e3f4d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomaly_id_00_00000079.wav tensor(0.0424, device='cuda:0')\n",
      "anomaly_id_04_00000012.wav tensor(0.0242, device='cuda:0')\n",
      "anomaly_id_04_00000070.wav tensor(0.0310, device='cuda:0')\n",
      "anomaly_id_00_00000219.wav tensor(0.0299, device='cuda:0')\n",
      "normal_id_00_00000020.wav tensor(0.0235, device='cuda:0')\n",
      "anomaly_id_04_00000105.wav tensor(0.0332, device='cuda:0')\n",
      "anomaly_id_04_00000029.wav tensor(0.0309, device='cuda:0')\n",
      "anomaly_id_02_00000254.wav tensor(0.0150, device='cuda:0')\n",
      "anomaly_id_04_00000073.wav tensor(0.0244, device='cuda:0')\n",
      "normal_id_04_00000030.wav tensor(0.0265, device='cuda:0')\n",
      "anomaly_id_04_00000102.wav tensor(0.0206, device='cuda:0')\n",
      "anomaly_id_00_00000086.wav tensor(0.0354, device='cuda:0')\n",
      "normal_id_00_00000091.wav tensor(0.0146, device='cuda:0')\n",
      "anomaly_id_02_00000128.wav tensor(0.0279, device='cuda:0')\n",
      "anomaly_id_02_00000105.wav tensor(0.0170, device='cuda:0')\n",
      "anomaly_id_00_00000336.wav tensor(0.0384, device='cuda:0')\n",
      "anomaly_id_02_00000033.wav tensor(0.0227, device='cuda:0')\n",
      "anomaly_id_02_00000002.wav tensor(0.0228, device='cuda:0')\n",
      "anomaly_id_04_00000001.wav tensor(0.0238, device='cuda:0')\n",
      "anomaly_id_02_00000219.wav tensor(0.0274, device='cuda:0')\n",
      "normal_id_02_00000026.wav tensor(0.0200, device='cuda:0')\n",
      "normal_id_02_00000037.wav tensor(0.0153, device='cuda:0')\n",
      "normal_id_04_00000038.wav tensor(0.0262, device='cuda:0')\n",
      "anomaly_id_00_00000080.wav tensor(0.0281, device='cuda:0')\n",
      "anomaly_id_00_00000081.wav tensor(0.0250, device='cuda:0')\n",
      "normal_id_04_00000095.wav tensor(0.0179, device='cuda:0')\n",
      "anomaly_id_00_00000143.wav tensor(0.0327, device='cuda:0')\n",
      "anomaly_id_04_00000165.wav tensor(0.0191, device='cuda:0')\n",
      "anomaly_id_00_00000325.wav tensor(0.0344, device='cuda:0')\n",
      "anomaly_id_02_00000143.wav tensor(0.0390, device='cuda:0')\n",
      "anomaly_id_02_00000120.wav tensor(0.0202, device='cuda:0')\n",
      "anomaly_id_04_00000169.wav tensor(0.0435, device='cuda:0')\n",
      "anomaly_id_02_00000197.wav tensor(0.0180, device='cuda:0')\n",
      "anomaly_id_04_00000022.wav tensor(0.0345, device='cuda:0')\n",
      "anomaly_id_02_00000171.wav tensor(0.0261, device='cuda:0')\n",
      "anomaly_id_00_00000228.wav tensor(0.0532, device='cuda:0')\n",
      "normal_id_02_00000020.wav tensor(0.0242, device='cuda:0')\n",
      "normal_id_02_00000066.wav tensor(0.0260, device='cuda:0')\n",
      "anomaly_id_04_00000056.wav tensor(0.0235, device='cuda:0')\n",
      "anomaly_id_04_00000116.wav tensor(0.0258, device='cuda:0')\n",
      "anomaly_id_04_00000151.wav tensor(0.0214, device='cuda:0')\n",
      "anomaly_id_00_00000329.wav tensor(0.0259, device='cuda:0')\n",
      "anomaly_id_02_00000222.wav tensor(0.0365, device='cuda:0')\n",
      "normal_id_02_00000017.wav tensor(0.0152, device='cuda:0')\n",
      "normal_id_04_00000004.wav tensor(0.0182, device='cuda:0')\n",
      "normal_id_00_00000027.wav tensor(0.0212, device='cuda:0')\n",
      "normal_id_04_00000085.wav tensor(0.0220, device='cuda:0')\n",
      "anomaly_id_04_00000074.wav tensor(0.0185, device='cuda:0')\n",
      "anomaly_id_00_00000031.wav tensor(0.0268, device='cuda:0')\n",
      "normal_id_00_00000037.wav tensor(0.0149, device='cuda:0')\n",
      "normal_id_04_00000072.wav tensor(0.0380, device='cuda:0')\n",
      "anomaly_id_04_00000077.wav tensor(0.0248, device='cuda:0')\n",
      "anomaly_id_02_00000049.wav tensor(0.0241, device='cuda:0')\n",
      "normal_id_00_00000047.wav tensor(0.0173, device='cuda:0')\n",
      "anomaly_id_02_00000065.wav tensor(0.0154, device='cuda:0')\n",
      "normal_id_00_00000042.wav tensor(0.0147, device='cuda:0')\n",
      "anomaly_id_04_00000119.wav tensor(0.0254, device='cuda:0')\n",
      "anomaly_id_00_00000051.wav tensor(0.0277, device='cuda:0')\n",
      "anomaly_id_02_00000029.wav tensor(0.0252, device='cuda:0')\n",
      "normal_id_02_00000049.wav tensor(0.0159, device='cuda:0')\n",
      "normal_id_00_00000051.wav tensor(0.0173, device='cuda:0')\n",
      "normal_id_02_00000061.wav tensor(0.0186, device='cuda:0')\n",
      "anomaly_id_04_00000040.wav tensor(0.0293, device='cuda:0')\n",
      "anomaly_id_00_00000133.wav tensor(0.0450, device='cuda:0')\n",
      "anomaly_id_00_00000222.wav tensor(0.0285, device='cuda:0')\n",
      "normal_id_02_00000097.wav tensor(0.0196, device='cuda:0')\n",
      "anomaly_id_00_00000131.wav tensor(0.0279, device='cuda:0')\n",
      "normal_id_02_00000016.wav tensor(0.0169, device='cuda:0')\n",
      "anomaly_id_04_00000111.wav tensor(0.0265, device='cuda:0')\n",
      "normal_id_02_00000010.wav tensor(0.0357, device='cuda:0')\n",
      "anomaly_id_04_00000005.wav tensor(0.0453, device='cuda:0')\n",
      "normal_id_00_00000014.wav tensor(0.0194, device='cuda:0')\n",
      "anomaly_id_04_00000153.wav tensor(0.0185, device='cuda:0')\n",
      "anomaly_id_00_00000233.wav tensor(0.0548, device='cuda:0')\n",
      "anomaly_id_04_00000025.wav tensor(0.0241, device='cuda:0')\n",
      "normal_id_02_00000085.wav tensor(0.0179, device='cuda:0')\n",
      "anomaly_id_04_00000024.wav tensor(0.0227, device='cuda:0')\n",
      "anomaly_id_02_00000183.wav tensor(0.0216, device='cuda:0')\n",
      "anomaly_id_04_00000148.wav tensor(0.0246, device='cuda:0')\n",
      "anomaly_id_00_00000301.wav tensor(0.0280, device='cuda:0')\n",
      "anomaly_id_04_00000055.wav tensor(0.0255, device='cuda:0')\n",
      "anomaly_id_00_00000181.wav tensor(0.0302, device='cuda:0')\n",
      "anomaly_id_00_00000176.wav tensor(0.0420, device='cuda:0')\n",
      "anomaly_id_02_00000152.wav tensor(0.0219, device='cuda:0')\n",
      "anomaly_id_02_00000253.wav tensor(0.0156, device='cuda:0')\n",
      "anomaly_id_02_00000246.wav tensor(0.0317, device='cuda:0')\n",
      "anomaly_id_00_00000151.wav tensor(0.0248, device='cuda:0')\n",
      "anomaly_id_00_00000166.wav tensor(0.0296, device='cuda:0')\n",
      "anomaly_id_00_00000098.wav tensor(0.0267, device='cuda:0')\n",
      "anomaly_id_02_00000264.wav tensor(0.0177, device='cuda:0')\n",
      "normal_id_00_00000061.wav tensor(0.0204, device='cuda:0')\n",
      "anomaly_id_00_00000215.wav tensor(0.0311, device='cuda:0')\n",
      "anomaly_id_02_00000054.wav tensor(0.0220, device='cuda:0')\n",
      "anomaly_id_04_00000043.wav tensor(0.0228, device='cuda:0')\n",
      "anomaly_id_02_00000116.wav tensor(0.0161, device='cuda:0')\n",
      "anomaly_id_00_00000226.wav tensor(0.0305, device='cuda:0')\n",
      "anomaly_id_00_00000135.wav tensor(0.0413, device='cuda:0')\n",
      "anomaly_id_00_00000334.wav tensor(0.0262, device='cuda:0')\n",
      "normal_id_00_00000007.wav tensor(0.0174, device='cuda:0')\n",
      "anomaly_id_04_00000006.wav tensor(0.0222, device='cuda:0')\n",
      "anomaly_id_00_00000256.wav tensor(0.0422, device='cuda:0')\n",
      "anomaly_id_04_00000167.wav tensor(0.0300, device='cuda:0')\n",
      "normal_id_00_00000028.wav tensor(0.0204, device='cuda:0')\n",
      "anomaly_id_00_00000209.wav tensor(0.0454, device='cuda:0')\n",
      "anomaly_id_02_00000127.wav tensor(0.0156, device='cuda:0')\n",
      "anomaly_id_04_00000060.wav tensor(0.0299, device='cuda:0')\n",
      "anomaly_id_00_00000316.wav tensor(0.0287, device='cuda:0')\n",
      "anomaly_id_02_00000139.wav tensor(0.0146, device='cuda:0')\n",
      "normal_id_02_00000086.wav tensor(0.0234, device='cuda:0')\n",
      "normal_id_04_00000073.wav tensor(0.0260, device='cuda:0')\n",
      "anomaly_id_02_00000247.wav tensor(0.0243, device='cuda:0')\n",
      "anomaly_id_00_00000001.wav tensor(0.0287, device='cuda:0')\n",
      "normal_id_04_00000036.wav tensor(0.0216, device='cuda:0')\n",
      "anomaly_id_00_00000324.wav tensor(0.0271, device='cuda:0')\n",
      "normal_id_00_00000050.wav tensor(0.0240, device='cuda:0')\n",
      "normal_id_00_00000054.wav tensor(0.0143, device='cuda:0')\n",
      "anomaly_id_00_00000084.wav tensor(0.0282, device='cuda:0')\n",
      "anomaly_id_02_00000168.wav tensor(0.0162, device='cuda:0')\n",
      "anomaly_id_04_00000113.wav tensor(0.0305, device='cuda:0')\n",
      "normal_id_02_00000044.wav tensor(0.0146, device='cuda:0')\n",
      "normal_id_00_00000032.wav tensor(0.0185, device='cuda:0')\n",
      "normal_id_04_00000033.wav tensor(0.0239, device='cuda:0')\n",
      "anomaly_id_02_00000218.wav tensor(0.0173, device='cuda:0')\n",
      "normal_id_04_00000056.wav tensor(0.0212, device='cuda:0')\n",
      "anomaly_id_04_00000152.wav tensor(0.0257, device='cuda:0')\n",
      "anomaly_id_00_00000340.wav tensor(0.0348, device='cuda:0')\n",
      "normal_id_00_00000040.wav tensor(0.0244, device='cuda:0')\n",
      "normal_id_00_00000090.wav tensor(0.0188, device='cuda:0')\n"
     ]
    }
   ],
   "execution_count": 89
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
