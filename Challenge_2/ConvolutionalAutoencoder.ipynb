{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-17T08:43:49.748258Z",
     "start_time": "2024-05-17T08:43:49.518414Z"
    }
   },
   "source": [
    "%reset -f\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "\n",
    "from customDatasets.audioDataset import AudioDataset\n"
   ],
   "outputs": [],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T08:43:49.753698Z",
     "start_time": "2024-05-17T08:43:49.750004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# free gpu\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ],
   "id": "f968c3c21dc371bb",
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T08:43:49.765410Z",
     "start_time": "2024-05-17T08:43:49.755559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ConvolutionalAE(nn.Module):\n",
    "    def __init__(self, encoding_dim):\n",
    "        super(ConvolutionalAE, self).__init__()\n",
    "        self.encoding_dim = encoding_dim\n",
    "        self.encoder = nn.Sequential(\n",
    "            # (320, 128)\n",
    "            nn.Conv2d(1, 32, kernel_size=5, stride=(1,2), padding=(2,2)),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            # (320, 64)\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=(1,2), padding=(2,2)),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            # (320, 32)\n",
    "            nn.Conv2d(64, 128, kernel_size=5, stride=(2,2), padding=(2,2)),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            # (160, 16)\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=(2,2), padding=(1,1)),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            # (80, 8)\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=(2,2), padding=(1,1)),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            # (40, 4, 512)\n",
    "        )\n",
    "               \n",
    "        # inflates the latent space to the shape of the last layer of the encoder\n",
    "        self.fc=nn.Sequential(\n",
    "            nn.Linear(512*40*4, self.encoding_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.encoding_dim, 512*40*4),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.decoder=nn.Sequential(\n",
    "            # (512, 40, 4)\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=3, stride=(2,2), padding=(1,1),output_padding=(1,1)),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            # (256, 80, 8)\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=(2,2), padding=(1,1),output_padding=(1,1)),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            # (128, 160, 16)\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=(2,2), padding=(1,1),output_padding=(1,1)),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            # (64, 320, 32)\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=5, stride=(1,2), padding=(2,2),output_padding=(0,1)),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            # (32, 320, 64)\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=5, stride=(1,2), padding=(2,2),output_padding=(0,1)),\n",
    "            # (1, 320, 128)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        encoded = encoded.view(-1, 512*40*4)\n",
    "        x=self.fc(encoded)\n",
    "        x = x.view(-1, 512, 40, 4)\n",
    "        decoded = self.decoder(x)\n",
    "        \n",
    "        return decoded"
   ],
   "id": "86b9d0ccc25a1707",
   "outputs": [],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T08:43:49.777086Z",
     "start_time": "2024-05-17T08:43:49.768135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model, train_dl, val_dl, test_dl, criterion, optimizer, device, epochs=5, step_size=5):\n",
    "    lr_scheduler=torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=0.1)\n",
    "    for epoch in range(epochs):\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "\n",
    "        for inputs, labels in train_dl:\n",
    "            model.train()\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, inputs)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "        lr_scheduler.step()\n",
    "        print(f'Epoch[{epoch + 1}/{epochs}], Train loss: {np.average(train_losses): .4f}')\n",
    "        \n",
    "        \n",
    "        for inputs, labels in val_dl:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, inputs)\n",
    "                val_losses.append(loss.item())\n",
    "        print(f'Epoch[{epoch + 1}/{epochs}], Val loss: {np.average(val_losses): .4f}')\n",
    " \n",
    "        scores = []\n",
    "        full_labels = []\n",
    "        for inputs, labels in test_dl:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                mse = torch.sum((outputs-inputs)**2,dim=(1,2,3))/(inputs.shape[1]*inputs.shape[2]*inputs.shape[3])            \n",
    "                scores.append(mse)\n",
    "                full_labels.append(labels)\n",
    "        \n",
    "        full_labels = torch.cat([label for label in full_labels])\n",
    "        scores = torch.cat([score for score in scores])\n",
    "        fpr, tpr, _ = roc_curve(full_labels.cpu().detach(), scores.cpu().detach(), pos_label=0)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        print(roc_auc)\n",
    "        \n",
    "    return np.average(train_losses),np.average(val_losses),roc_auc"
   ],
   "id": "f56f0745d3302d87",
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T08:43:49.792963Z",
     "start_time": "2024-05-17T08:43:49.778581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def set_seed(seed = 42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "CONFIG = {\n",
    "    \"seed\": 42,\n",
    "    \"epochs\": 10,\n",
    "    \"num_classes\": 2,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"train_batch_size\": 32,\n",
    "    \"val_batch_size\": 16,\n",
    "    \"test_batch_size\": 128,\n",
    "    \"criterion\": nn.MSELoss(),\n",
    "    \"device\":\n",
    "        torch.device(\n",
    "            \"cuda:0\" if torch.cuda.is_available()\n",
    "            else \"mps\" if torch.backends.mps.is_available()\n",
    "            else \"cpu\"\n",
    "        )\n",
    "}\n",
    "\n",
    "set_seed(CONFIG['seed'])\n",
    "\n",
    "data_path = \"./data/train/\"\n",
    "data_path_test = \"./data/test/\"\n",
    "\n",
    "\n",
    "meta_train_df = pd.read_csv(\"./data/train.csv\")\n",
    "meta_test_df = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "train_df = meta_train_df[['filename', 'is_normal', 'machine_id']]\n",
    "train_ds = AudioDataset(train_df, data_path)\n",
    "test_df = meta_test_df[['filename', 'is_normal', 'machine_id']]\n",
    "test_ds = AudioDataset(test_df, data_path_test)\n",
    "\n",
    "num_items = len(train_ds)\n",
    "num_train = int(0.8 * num_items)\n",
    "num_val = num_items-num_train\n",
    "\n",
    "train_ds, val_ds = random_split(train_ds, [num_train, num_val])\n",
    "test_ds = test_ds\n",
    "\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=CONFIG['train_batch_size'], shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=CONFIG['val_batch_size'], shuffle=False)\n",
    "test_dl = DataLoader(test_ds, batch_size=CONFIG[\"test_batch_size\"], shuffle=False)"
   ],
   "id": "36ce87d24bd72ad5",
   "outputs": [],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T08:43:50.071987Z",
     "start_time": "2024-05-17T08:43:49.794291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = ConvolutionalAE(encoding_dim=128)\n",
    "model = model.to(CONFIG[\"device\"])\n",
    "optimizer = optim.Adam(model.parameters(), lr=CONFIG[\"learning_rate\"])\n",
    "for batch in train_dl:\n",
    "    inputs, labels = batch\n",
    "    print(inputs.shape)\n",
    "    inputs = inputs.to(CONFIG[\"device\"])\n",
    "    outputs = model(inputs)\n",
    "    print(outputs.shape)\n",
    "    break"
   ],
   "id": "8b01c9d83af18dc7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 320, 128])\n",
      "torch.Size([32, 1, 320, 128])\n"
     ]
    }
   ],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T08:43:55.915472Z",
     "start_time": "2024-05-17T08:43:50.073118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# compute metrics\n",
    "inputs_cat=[]\n",
    "for inputs, labels in train_dl:\n",
    "    inputs_cat.append(inputs)\n",
    "inputs_cat = torch.cat([input for input in inputs_cat])\n",
    "print(inputs_cat.shape)"
   ],
   "id": "ed6681960638cdc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1896, 1, 320, 128])\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T08:43:56.179932Z",
     "start_time": "2024-05-17T08:43:55.916716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# compute the min and max value for each frequency of the batch_sizexchannelxtimexfrequecy\n",
    "min = torch.min(inputs_cat, dim=0).values\n",
    "max = torch.max(inputs_cat, dim=0).values\n",
    "print(max.shape)\n",
    "print(min.shape)\n",
    "train_ds.min = min\n",
    "train_ds.max = max\n",
    "test_ds.min = min\n",
    "test_ds.max = max\n",
    "val_ds.min = min\n",
    "val_ds.max = max"
   ],
   "id": "8da7699198b628fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 320, 128])\n",
      "torch.Size([1, 320, 128])\n"
     ]
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T09:03:01.491974Z",
     "start_time": "2024-05-17T08:43:56.181356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "measures = []\n",
    "for emb_space_size in [32, 64, 128, 256, 512]:\n",
    "    model = ConvolutionalAE(encoding_dim=emb_space_size)\n",
    "    model = model.to(CONFIG[\"device\"])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=CONFIG[\"learning_rate\"])\n",
    "    measures.append(train_model(model, train_dl, val_dl, test_dl, CONFIG[\"criterion\"], optimizer, CONFIG[\"device\"], CONFIG[\"epochs\"]))\n",
    "for emb_space_size, measure in zip([32, 64, 128, 256, 512], measures):\n",
    "    print(f\"Emb space size: {emb_space_size}, Train loss: {measure[0]}, Val loss: {measure[1]}, ROC AUC: {measure[2]}\")"
   ],
   "id": "612f0834c93b8867",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/10], Train loss:  41.2674\n",
      "Epoch[1/10], Val loss:  21.4426\n",
      "0.8055035372451103\n",
      "Epoch[2/10], Train loss:  20.8006\n",
      "Epoch[2/10], Val loss:  23.4689\n",
      "0.8045900957136912\n",
      "Epoch[3/10], Train loss:  20.1312\n",
      "Epoch[3/10], Val loss:  20.5690\n",
      "0.80867873491469\n",
      "Epoch[4/10], Train loss:  19.3681\n",
      "Epoch[4/10], Val loss:  26.0973\n",
      "0.8094881398252185\n",
      "Epoch[5/10], Train loss:  18.9961\n",
      "Epoch[5/10], Val loss:  18.4890\n",
      "0.8039741989180191\n",
      "Epoch[6/10], Train loss:  18.6282\n",
      "Epoch[6/10], Val loss:  18.3041\n",
      "0.8074531835205994\n",
      "Epoch[7/10], Train loss:  18.4152\n",
      "Epoch[7/10], Val loss:  18.1432\n",
      "0.8082188930503538\n",
      "Epoch[8/10], Train loss:  18.2431\n",
      "Epoch[8/10], Val loss:  18.1522\n",
      "0.8064086558468581\n",
      "Epoch[9/10], Train loss:  18.2286\n",
      "Epoch[9/10], Val loss:  18.0469\n",
      "0.8114024136496047\n",
      "Epoch[10/10], Train loss:  18.1372\n",
      "Epoch[10/10], Val loss:  18.1185\n",
      "0.8083062838119017\n",
      "Epoch[1/10], Train loss:  36.9517\n",
      "Epoch[1/10], Val loss:  23.6796\n",
      "0.8081960049937578\n",
      "Epoch[2/10], Train loss:  21.1943\n",
      "Epoch[2/10], Val loss:  20.5794\n",
      "0.8078818143986684\n",
      "Epoch[3/10], Train loss:  20.4313\n",
      "Epoch[3/10], Val loss:  20.5011\n",
      "0.8027174365376613\n",
      "Epoch[4/10], Train loss:  19.4290\n",
      "Epoch[4/10], Val loss:  19.1431\n",
      "0.8047107781939242\n",
      "Epoch[5/10], Train loss:  19.1628\n",
      "Epoch[5/10], Val loss:  18.6709\n",
      "0.8058343736995423\n",
      "Epoch[6/10], Train loss:  18.4228\n",
      "Epoch[6/10], Val loss:  18.3341\n",
      "0.8024406991260924\n",
      "Epoch[7/10], Train loss:  18.2983\n",
      "Epoch[7/10], Val loss:  17.8873\n",
      "0.803270911360799\n",
      "Epoch[8/10], Train loss:  18.0396\n",
      "Epoch[8/10], Val loss:  17.9616\n",
      "0.8021410736579276\n",
      "Epoch[9/10], Train loss:  17.9330\n",
      "Epoch[9/10], Val loss:  17.6534\n",
      "0.7986100707449023\n",
      "Epoch[10/10], Train loss:  17.7438\n",
      "Epoch[10/10], Val loss:  17.4565\n",
      "0.7978547648772368\n",
      "Epoch[1/10], Train loss:  41.9642\n",
      "Epoch[1/10], Val loss:  22.5433\n",
      "0.8099209321681232\n",
      "Epoch[2/10], Train loss:  21.6388\n",
      "Epoch[2/10], Val loss:  21.0087\n",
      "0.8155534748231377\n",
      "Epoch[3/10], Train loss:  20.6624\n",
      "Epoch[3/10], Val loss:  20.8573\n",
      "0.8111090303786932\n",
      "Epoch[4/10], Train loss:  20.2506\n",
      "Epoch[4/10], Val loss:  19.6105\n",
      "0.8021057012068248\n",
      "Epoch[5/10], Train loss:  19.6099\n",
      "Epoch[5/10], Val loss:  20.7041\n",
      "0.8101727007906784\n",
      "Epoch[6/10], Train loss:  19.0127\n",
      "Epoch[6/10], Val loss:  18.8955\n",
      "0.8102559300873908\n",
      "Epoch[7/10], Train loss:  18.8953\n",
      "Epoch[7/10], Val loss:  18.7474\n",
      "0.8036308780690804\n",
      "Epoch[8/10], Train loss:  18.8297\n",
      "Epoch[8/10], Val loss:  18.5314\n",
      "0.8052392842280482\n",
      "Epoch[9/10], Train loss:  18.7114\n",
      "Epoch[9/10], Val loss:  18.4868\n",
      "0.8098751560549313\n",
      "Epoch[10/10], Train loss:  18.6468\n",
      "Epoch[10/10], Val loss:  18.5725\n",
      "0.8126217228464419\n",
      "Epoch[1/10], Train loss:  41.5011\n",
      "Epoch[1/10], Val loss:  23.0395\n",
      "0.8080565959217645\n",
      "Epoch[2/10], Train loss:  21.5541\n",
      "Epoch[2/10], Val loss:  20.3763\n",
      "0.8077798585101956\n",
      "Epoch[3/10], Train loss:  20.4695\n",
      "Epoch[3/10], Val loss:  19.6751\n",
      "0.805936329588015\n",
      "Epoch[4/10], Train loss:  19.6283\n",
      "Epoch[4/10], Val loss:  19.2096\n",
      "0.7966292134831461\n",
      "Epoch[5/10], Train loss:  19.1532\n",
      "Epoch[5/10], Val loss:  18.9935\n",
      "0.8017415730337079\n",
      "Epoch[6/10], Train loss:  18.7224\n",
      "Epoch[6/10], Val loss:  18.6697\n",
      "0.8007573866000832\n",
      "Epoch[7/10], Train loss:  18.6534\n",
      "Epoch[7/10], Val loss:  18.3451\n",
      "0.809184352892218\n",
      "Epoch[8/10], Train loss:  18.5596\n",
      "Epoch[8/10], Val loss:  18.2895\n",
      "0.8040158135663753\n",
      "Epoch[9/10], Train loss:  18.4890\n",
      "Epoch[9/10], Val loss:  18.2002\n",
      "0.8010403662089056\n",
      "Epoch[10/10], Train loss:  18.4425\n",
      "Epoch[10/10], Val loss:  18.4364\n",
      "0.8053245942571785\n",
      "Epoch[1/10], Train loss:  37.8070\n",
      "Epoch[1/10], Val loss:  24.5497\n",
      "0.8102205576362882\n",
      "Epoch[2/10], Train loss:  21.1616\n",
      "Epoch[2/10], Val loss:  20.6273\n",
      "0.8088639200998751\n",
      "Epoch[3/10], Train loss:  20.3458\n",
      "Epoch[3/10], Val loss:  20.5852\n",
      "0.8123699542238868\n",
      "Epoch[4/10], Train loss:  19.9500\n",
      "Epoch[4/10], Val loss:  20.8353\n",
      "0.8107532251352476\n",
      "Epoch[5/10], Train loss:  19.4062\n",
      "Epoch[5/10], Val loss:  19.3802\n",
      "0.7990886392009988\n",
      "Epoch[6/10], Train loss:  18.8050\n",
      "Epoch[6/10], Val loss:  18.4979\n",
      "0.8089533915938409\n",
      "Epoch[7/10], Train loss:  18.5301\n",
      "Epoch[7/10], Val loss:  18.2977\n",
      "0.8047815230961299\n",
      "Epoch[8/10], Train loss:  18.5037\n",
      "Epoch[8/10], Val loss:  18.2740\n",
      "0.8051310861423221\n",
      "Epoch[9/10], Train loss:  18.4333\n",
      "Epoch[9/10], Val loss:  18.3645\n",
      "0.8070994590095715\n",
      "Epoch[10/10], Train loss:  18.3465\n",
      "Epoch[10/10], Val loss:  18.1027\n",
      "0.8099209321681231\n",
      "Emb space size: 32, Train loss: 18.13722235361735, Val loss: 18.118455346425375, ROC AUC: 0.8083062838119017\n",
      "Emb space size: 64, Train loss: 17.743754959106447, Val loss: 17.456455580393474, ROC AUC: 0.7978547648772368\n",
      "Emb space size: 128, Train loss: 18.64676882425944, Val loss: 18.572460428873697, ROC AUC: 0.8126217228464419\n",
      "Emb space size: 256, Train loss: 18.442458788553875, Val loss: 18.43639980951945, ROC AUC: 0.8053245942571785\n",
      "Emb space size: 512, Train loss: 18.346508502960205, Val loss: 18.102725060780845, ROC AUC: 0.8099209321681231\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T09:45:54.260923Z",
     "start_time": "2024-05-17T09:27:26.384173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# take the best one and train it for more epochs\n",
    "emb_space_measures=[32, 64, 128, 256, 512]\n",
    "model = ConvolutionalAE(encoding_dim=emb_space_measures[np.argmax([measure[2] for measure in measures])])\n",
    "model = model.to(CONFIG[\"device\"])"
   ],
   "id": "b7de0bec6b2f58e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/50], Train loss:  108.8960\n",
      "Epoch[1/50], Val loss:  30.5281\n",
      "0.8054806491885143\n",
      "Epoch[2/50], Train loss:  23.0877\n",
      "Epoch[2/50], Val loss:  20.7735\n",
      "0.8127590511860175\n",
      "Epoch[3/50], Train loss:  19.4100\n",
      "Epoch[3/50], Val loss:  18.4904\n",
      "0.7987702871410737\n",
      "Epoch[4/50], Train loss:  18.4952\n",
      "Epoch[4/50], Val loss:  17.5310\n",
      "0.8085518102372036\n",
      "Epoch[5/50], Train loss:  17.3512\n",
      "Epoch[5/50], Val loss:  17.4059\n",
      "0.8068705784436122\n",
      "Epoch[6/50], Train loss:  16.4580\n",
      "Epoch[6/50], Val loss:  16.1948\n",
      "0.8077153558052435\n",
      "Epoch[7/50], Train loss:  15.8361\n",
      "Epoch[7/50], Val loss:  16.6327\n",
      "0.8123741156887223\n",
      "Epoch[8/50], Train loss:  15.2831\n",
      "Epoch[8/50], Val loss:  15.4545\n",
      "0.8074157303370786\n",
      "Epoch[9/50], Train loss:  14.7621\n",
      "Epoch[9/50], Val loss:  14.4026\n",
      "0.8030316271327507\n",
      "Epoch[10/50], Train loss:  14.6060\n",
      "Epoch[10/50], Val loss:  14.6483\n",
      "0.8075260091552227\n",
      "Epoch[11/50], Train loss:  14.4223\n",
      "Epoch[11/50], Val loss:  15.0697\n",
      "0.803899292550978\n",
      "Epoch[12/50], Train loss:  14.1682\n",
      "Epoch[12/50], Val loss:  13.7443\n",
      "0.8072846441947565\n",
      "Epoch[13/50], Train loss:  13.5324\n",
      "Epoch[13/50], Val loss:  13.9699\n",
      "0.8087141073657929\n",
      "Epoch[14/50], Train loss:  13.4038\n",
      "Epoch[14/50], Val loss:  13.1153\n",
      "0.8112359550561798\n",
      "Epoch[15/50], Train loss:  12.9986\n",
      "Epoch[15/50], Val loss:  13.4076\n",
      "0.8078984602580108\n",
      "Epoch[16/50], Train loss:  12.8678\n",
      "Epoch[16/50], Val loss:  12.8021\n",
      "0.813689138576779\n",
      "Epoch[17/50], Train loss:  12.7787\n",
      "Epoch[17/50], Val loss:  13.0877\n",
      "0.8068393674573451\n",
      "Epoch[18/50], Train loss:  12.3411\n",
      "Epoch[18/50], Val loss:  12.4095\n",
      "0.8077028714107367\n",
      "Epoch[19/50], Train loss:  12.3319\n",
      "Epoch[19/50], Val loss:  12.6698\n",
      "0.8078339575530586\n",
      "Epoch[20/50], Train loss:  12.1045\n",
      "Epoch[20/50], Val loss:  12.3272\n",
      "0.8085559717020392\n",
      "Epoch[21/50], Train loss:  12.1308\n",
      "Epoch[21/50], Val loss:  12.1177\n",
      "0.8078401997503122\n",
      "Epoch[22/50], Train loss:  11.8914\n",
      "Epoch[22/50], Val loss:  11.9152\n",
      "0.8111069496462755\n",
      "Epoch[23/50], Train loss:  11.6827\n",
      "Epoch[23/50], Val loss:  12.2652\n",
      "0.8117686225551394\n",
      "Epoch[24/50], Train loss:  11.7508\n",
      "Epoch[24/50], Val loss:  11.8547\n",
      "0.806179775280899\n",
      "Epoch[25/50], Train loss:  11.6079\n",
      "Epoch[25/50], Val loss:  12.2079\n",
      "0.8121098626716603\n",
      "Epoch[26/50], Train loss:  11.2511\n",
      "Epoch[26/50], Val loss:  11.1734\n",
      "0.8069787765293384\n",
      "Epoch[27/50], Train loss:  11.1257\n",
      "Epoch[27/50], Val loss:  11.1538\n",
      "0.8111943404078235\n",
      "Epoch[28/50], Train loss:  11.0734\n",
      "Epoch[28/50], Val loss:  11.1629\n",
      "0.8091448189762797\n",
      "Epoch[29/50], Train loss:  11.0479\n",
      "Epoch[29/50], Val loss:  11.2113\n",
      "0.8115168539325843\n",
      "Epoch[30/50], Train loss:  11.0081\n",
      "Epoch[30/50], Val loss:  11.1696\n",
      "0.8074594257178528\n",
      "Epoch[31/50], Train loss:  10.9465\n",
      "Epoch[31/50], Val loss:  11.0574\n",
      "0.8068143986683312\n",
      "Epoch[32/50], Train loss:  10.9436\n",
      "Epoch[32/50], Val loss:  11.0576\n",
      "0.8142946317103619\n",
      "Epoch[33/50], Train loss:  10.9264\n",
      "Epoch[33/50], Val loss:  11.0013\n",
      "0.8030212234706617\n",
      "Epoch[34/50], Train loss:  10.9002\n",
      "Epoch[34/50], Val loss:  10.9867\n",
      "0.8064814814814815\n",
      "Epoch[35/50], Train loss:  10.9250\n",
      "Epoch[35/50], Val loss:  11.0591\n",
      "0.8117748647523928\n",
      "Epoch[36/50], Train loss:  10.8266\n",
      "Epoch[36/50], Val loss:  11.0467\n",
      "0.8106845609654598\n",
      "Epoch[37/50], Train loss:  10.8475\n",
      "Epoch[37/50], Val loss:  10.9383\n",
      "0.8120557636287973\n",
      "Epoch[38/50], Train loss:  10.8462\n",
      "Epoch[38/50], Val loss:  11.0364\n",
      "0.8071764461090304\n",
      "Epoch[39/50], Train loss:  10.8467\n",
      "Epoch[39/50], Val loss:  10.9559\n",
      "0.8084477736163129\n",
      "Epoch[40/50], Train loss:  10.8105\n",
      "Epoch[40/50], Val loss:  10.8882\n",
      "0.8112380357885977\n",
      "Epoch[41/50], Train loss:  10.7965\n",
      "Epoch[41/50], Val loss:  10.9236\n",
      "0.8089180191427383\n",
      "Epoch[42/50], Train loss:  10.7646\n",
      "Epoch[42/50], Val loss:  10.8986\n",
      "0.8090928006658344\n",
      "Epoch[43/50], Train loss:  10.8671\n",
      "Epoch[43/50], Val loss:  10.8715\n",
      "0.808976279650437\n",
      "Epoch[44/50], Train loss:  10.7024\n",
      "Epoch[44/50], Val loss:  10.8564\n",
      "0.811333749479817\n",
      "Epoch[45/50], Train loss:  10.6984\n",
      "Epoch[45/50], Val loss:  10.8192\n",
      "0.8091885143570536\n",
      "Epoch[46/50], Train loss:  10.7287\n",
      "Epoch[46/50], Val loss:  10.8535\n",
      "0.8094111527257595\n",
      "Epoch[47/50], Train loss:  10.7161\n",
      "Epoch[47/50], Val loss:  10.8912\n",
      "0.8083832709113608\n",
      "Epoch[48/50], Train loss:  10.7204\n",
      "Epoch[48/50], Val loss:  10.9246\n",
      "0.8110216396171452\n",
      "Epoch[49/50], Train loss:  10.6289\n",
      "Epoch[49/50], Val loss:  10.6916\n",
      "0.8105285060341241\n",
      "Epoch[50/50], Train loss:  10.6023\n",
      "Epoch[50/50], Val loss:  10.8134\n",
      "0.8083270911360799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10.602347278594971, 10.813386599222818, 0.8083270911360799)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-05-17T10:39:07.651544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=+0.0001)\n",
    "#save weights into weights/weights.pth\n",
    "torch.save(model.state_dict(), \"./weights/weights.pth\")\n",
    "train_model(model, train_dl, val_dl, test_dl, CONFIG[\"criterion\"], optimizer, CONFIG[\"device\"], 50, 25)"
   ],
   "id": "acae56582dfab61b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
