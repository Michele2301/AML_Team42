{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-28T09:57:12.236848Z",
     "start_time": "2024-05-28T09:57:08.201334Z"
    }
   },
   "source": [
    "%reset -f\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from customDatasets.audioDataset import AudioDataset\n",
    "from torchviz import make_dot\n",
    "import hiddenlayer as hl"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T09:57:13.887932Z",
     "start_time": "2024-05-28T09:57:12.238399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# free gpu\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ],
   "id": "e75665b44fb4b2fb",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-05-28T09:57:46.053397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def set_seed(seed = 42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "CONFIG = {\n",
    "    \"seed\": 42,\n",
    "    \"epochs\": 20,\n",
    "    \"num_classes\": 2,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"train_batch_size\": 32,\n",
    "    \"val_batch_size\": 32,\n",
    "    \"test_batch_size\": 128,\n",
    "    \"criterion\": nn.MSELoss(),\n",
    "    \"noise\": torch.randn_like,\n",
    "    \"device\":\n",
    "        torch.device(\n",
    "            \"cuda:0\" if torch.cuda.is_available()\n",
    "            else \"mps\" if torch.backends.mps.is_available()\n",
    "            else \"cpu\"\n",
    "        )\n",
    "}\n",
    "\n",
    "print(CONFIG[\"device\"])\n",
    "set_seed(CONFIG['seed'])\n",
    "\n",
    "data_path = \"./data/train/\"\n",
    "data_path_test = \"./data/test/\"\n",
    "\n",
    "\n",
    "meta_train_df = pd.read_csv(\"./data/train.csv\")\n",
    "meta_test_df = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "train_df = meta_train_df[['filename', 'is_normal', 'machine_id']]\n",
    "range_train, range_test = train_test_split(range(len(train_df)), test_size=0.2, train_size=0.8, random_state=None, shuffle=True, stratify=meta_train_df['machine_id'])\n",
    "val_df = train_df.iloc[range_test].reset_index(drop=True)\n",
    "train_df = train_df.iloc[range_train].reset_index(drop=True)\n",
    "train_dataset = AudioDataset(train_df, data_path, sgram_type=\"mel\", augment=True, split_sgram=True, in_memory=True)\n",
    "val_dataset = AudioDataset(val_df, data_path, sgram_type=\"mel\", augment=False, test_mode=True, in_memory=True)\n",
    "test_df = meta_test_df[['filename', 'is_normal', 'machine_id']]\n",
    "test_dataset = AudioDataset(test_df, data_path_test, sgram_type=\"mel\", augment=False, test_mode=True, in_memory=True)\n",
    "\n",
    "train_ds = train_dataset\n",
    "val_ds = val_dataset\n",
    "test_ds = test_dataset\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=CONFIG['train_batch_size'], shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=CONFIG['val_batch_size'], shuffle=False)\n",
    "test_dl = DataLoader(test_ds, batch_size=CONFIG[\"test_batch_size\"], shuffle=False)\n",
    "input_size = next(iter(train_dl))[0].shape[1] * next(iter(train_dl))[0].shape[2] * next(iter(train_dl))[0].shape[3]\n",
    "print(input_size)"
   ],
   "id": "c9b61b810f2b3d8e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d05dd4d8856038f3"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# compute metrics\n",
    "inputs_cat=[]\n",
    "for inputs, labels in train_dl:\n",
    "    inputs_cat.append(inputs)\n",
    "inputs_cat = torch.cat(inputs_cat,dim=0)\n",
    "print(inputs_cat.shape)"
   ],
   "id": "4e59ca0e0008eff3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# compute the mean and std value for each frequency of the batch_sizexchannelxtimexfrequecy\n",
    "mean = torch.mean(inputs_cat, dim=0)\n",
    "std = torch.std(inputs_cat, dim=0)\n",
    "print(mean.shape)\n",
    "print(std.shape)\n",
    "train_dataset.mean = mean\n",
    "train_dataset.std = std\n",
    "val_dataset.mean = mean\n",
    "val_dataset.std = std\n",
    "test_dataset.mean = mean\n",
    "test_dataset.std = std"
   ],
   "id": "f94ba6211ddaca48",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torch.cuda.empty_cache()\n",
    "from diffusers import UNet2DModel\n",
    "print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
    "model = UNet2DModel(in_channels=1,\n",
    "                    out_channels=1,\n",
    "                    sample_size=(mean.shape[1],mean.shape[2]), # the target image resolution\n",
    "                    block_out_channels=(128,128,256,256,512,512), # the numbe of output channels for eaxh UNet block\n",
    "                    down_block_types=(\n",
    "                        \"DownBlock2D\", # a regular ResNet downsampling block\n",
    "                        \"DownBlock2D\",\n",
    "                        \"DownBlock2D\",\n",
    "                        \"DownBlock2D\",\n",
    "                        \"AttnDownBlock2D\", # a ResNet downsampling block with spatial self-attention\n",
    "                        \"DownBlock2D\",\n",
    "                    ),\n",
    "                    up_block_types=(\n",
    "                        \"UpBlock2D\", # a regular ResNet upsampling block\n",
    "                        \"AttnUpBlock2D\", # a ResNet upsampling block with spatial self-attention\n",
    "                        \"UpBlock2D\",\n",
    "                        \"UpBlock2D\",\n",
    "                        \"UpBlock2D\",\n",
    "                        \"UpBlock2D\",\n",
    "                    ),\n",
    "                   )\n",
    "model.to(CONFIG['device'])\n",
    "print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))"
   ],
   "id": "4c48bfad0b79374e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "optimizer = optim.Adam(model.parameters(), lr=0.0001)",
   "id": "1f4424ee38c63a26"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# training in a diffusion way, by adding gaussian noise to the input data and then doing the mse between the reconstructed data and the original data\n",
    "for epoch in range(CONFIG['epochs']):\n",
    "    lr_scheduler=torch.optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)\n",
    "    model.train()\n",
    "    for i, (x, y) in enumerate(train_dl):\n",
    "        # add gaussian noise with time t\n",
    "        # 32, 1 ,32 ,128\n",
    "        t=torch.rand(x.shape[0])\n",
    "        noisy_x = x+torch.cat([(t[i].unsqueeze(0) * CONFIG['noise'](x[0])).view(1,x[0].shape[0],x[0].shape[1],x[0].shape[2]) for i in range(len(t))], dim=0)\n",
    "        # 32,1,32,128\n",
    "        noisy_x=noisy_x.to(CONFIG['device'])\n",
    "        t=t.to(CONFIG['device'])\n",
    "        x=x.to(CONFIG['device'])\n",
    "        denoised_x=model(noisy_x,t)\n",
    "        loss=CONFIG['criterion'](denoised_x.sample, x)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # do a \n",
    "        if i % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, iter {i}, loss: {loss.item()}\")\n",
    "    full_scores = []\n",
    "    full_labels = []\n",
    "    for inputs, labels in test_dl:\n",
    "        inputs = inputs.view(inputs.shape[0],inputs.shape[1],1,inputs.shape[2],inputs.shape[3])\n",
    "        inputs, labels = inputs.to(CONFIG[\"device\"]), labels.to(CONFIG[\"device\"])\n",
    "        model.eval()\n",
    "        # 128, 10, 1, 32, 128\n",
    "        with torch.no_grad():\n",
    "            tmp_scores = []\n",
    "            for idx in range (10):\n",
    "                t=torch.rand(inputs.shape[0])\n",
    "                t=t.to(CONFIG['device'])\n",
    "                # 1,10\n",
    "                inputs_noised=inputs+torch.cat([(t[i].unsqueeze(0)*CONFIG['noise'](inputs[0])).view(1,*(inputs[0].shape)) for i in range(len(t))])\n",
    "                inputs_noised=inputs_noised.to(CONFIG['device'])\n",
    "                outputs = model(inputs_noised[:, idx, :, :, :],t)\n",
    "                mse = torch.sum((outputs.sample.view(outputs.sample.shape[0],-1) - inputs[:, idx, :, :, :].view(inputs.size(0), -1)) ** 2, dim=1, keepdim=True) / outputs.sample.shape[1]\n",
    "                tmp_scores.append(mse)\n",
    "            scores = torch.cat(tmp_scores, dim=1)\n",
    "            scores = torch.max(scores, dim=1).values\n",
    "            full_scores.append(scores)\n",
    "            full_labels.append(labels)\n",
    "        \n",
    "    full_labels = torch.cat([label for label in full_labels])\n",
    "    full_scores = torch.cat([score for score in full_scores])\n",
    "    fpr, tpr, _ = roc_curve(full_labels.cpu().detach(), full_scores.cpu().detach(), pos_label=0)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(roc_auc)\n",
    "        "
   ],
   "id": "973b9d825fc56a22",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
