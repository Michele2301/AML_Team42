{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "from customDatasets.audioDataset import AudioDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# free gpu\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.5131357e+02  1.0086341e+02 -1.0051440e+01  2.8362326e+01\n",
      "  5.0546038e-01  1.4227257e+01 -4.3528104e+00  3.0120912e+00\n",
      " -3.3442781e+00  3.2717636e+00 -2.8724821e+00 -3.4457836e-01\n",
      "  4.8515433e-01  5.5663044e+01  2.6887306e+01  2.2144478e+01\n",
      "  1.6949223e+01  1.6398485e+01  1.7218737e+01  1.6001156e+01\n",
      "  1.6644236e+01  1.8200521e+01  1.7958870e+01  1.5473613e+01\n",
      "  1.5308606e+01  1.5064983e+01]\n",
      "(26,)\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def extract_mfccs(audio_path, n_mfcc=13, sr=16000, hop_length=512, n_fft=1024):\n",
    "    # Load audio file\n",
    "    y, sr = librosa.load(audio_path, sr=sr)\n",
    "    \n",
    "    # Extract MFCCs\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc, hop_length=hop_length, n_fft=n_fft)\n",
    "    \n",
    "    # Compute mean and variance for each MFCC coefficient over all frames\n",
    "    mfccs_mean = np.mean(mfccs, axis=1)\n",
    "    mfccs_var = np.var(mfccs, axis=1)\n",
    "    \n",
    "    # Combine mean and variance into a single feature vector\n",
    "    mfccs_features = np.concatenate((mfccs_mean, mfccs_var))\n",
    "    \n",
    "    return mfccs_features\n",
    "\n",
    "# Example usage\n",
    "audio_path = \"./data/train/normal_id_00_00000000.wav\"\n",
    "mfcc_features = extract_mfccs(audio_path)\n",
    "print(mfcc_features)\n",
    "print(mfcc_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load training and test dataset\n",
    "\n",
    "def set_seed(seed = 42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "data_path = \"./data/train/\"\n",
    "data_path_test = \"./data/test/\"\n",
    "\n",
    "\n",
    "meta_train_df = pd.read_csv(\"./data/train.csv\")\n",
    "meta_test_df = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "train_df = meta_train_df[['filename', 'is_normal', 'machine_id']]\n",
    "range_train, range_test = train_test_split(range(len(train_df)), test_size=0.2, train_size=0.8, random_state=None, shuffle=True, stratify=meta_train_df['machine_id'])\n",
    "\n",
    "val_df = train_df.iloc[range_test].reset_index(drop=True)\n",
    "\n",
    "train_df = train_df.iloc[range_train].reset_index(drop=True)\n",
    "\n",
    "test_df = meta_test_df[['filename', 'is_normal', 'machine_id']]\n",
    "\n",
    "train_audios = []\n",
    "val_audios = []\n",
    "test_audios = []\n",
    "test_labels = []\n",
    "\n",
    "\n",
    "for idx in range(len(train_df)):\n",
    "    audio_file = data_path + train_df.loc[idx, 'filename']\n",
    "    aud = extract_mfccs(audio_file)\n",
    "    train_audios.append(aud)\n",
    "\n",
    "for idx in range(len(val_df)):\n",
    "    audio_file = data_path + val_df.loc[idx, 'filename']\n",
    "    aud = extract_mfccs(audio_file)\n",
    "    val_audios.append(aud)\n",
    "\n",
    "for idx in range(len(test_df)):\n",
    "    audio_file = data_path_test + test_df.loc[idx, 'filename']\n",
    "    aud = extract_mfccs(audio_file)\n",
    "    test_audios.append(aud)\n",
    "    test_labels.append(test_df.loc[idx, 'is_normal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1896, 26)\n",
      "(474, 26)\n",
      "(1101, 26)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = np.array(train_audios)\n",
    "val_dataset = np.array(val_audios)\n",
    "test_dataset = np.array(test_audios)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "print(train_dataset.shape)\n",
    "print(val_dataset.shape)\n",
    "print(test_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1101,)\n",
      "0.7974469413233458\n"
     ]
    }
   ],
   "source": [
    "gmm = GaussianMixture(n_components=4)\n",
    "gmm.fit(train_dataset)\n",
    "\n",
    "scores = gmm.predict(test_dataset)\n",
    "\n",
    "print(scores.shape)\n",
    "\n",
    "fpr, tpr, _ = roc_curve(test_labels, scores, pos_label=0)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(roc_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
