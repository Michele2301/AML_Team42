{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "from customDatasets.audioDataset import AudioDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# free gpu\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load training and test dataset\n",
    "\n",
    "def set_seed(seed = 42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "data_path = \"./data/train/\"\n",
    "data_path_test = \"./data/test/\"\n",
    "\n",
    "\n",
    "meta_train_df = pd.read_csv(\"./data/train.csv\")\n",
    "meta_test_df = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "train_df = meta_train_df[['filename', 'is_normal', 'machine_id']]\n",
    "range_train, range_test = train_test_split(range(len(train_df)), test_size=0.2, train_size=0.8, random_state=None, shuffle=True, stratify=meta_train_df['machine_id'])\n",
    "\n",
    "val_df = train_df.iloc[range_test].reset_index(drop=True)\n",
    "\n",
    "train_df = train_df.iloc[range_train].reset_index(drop=True)\n",
    "\n",
    "test_df = meta_test_df[['filename', 'is_normal', 'machine_id']]\n",
    "\n",
    "train_audios = []\n",
    "val_audios = []\n",
    "test_audios = []\n",
    "test_labels = []\n",
    "\n",
    "\n",
    "for idx in range(len(train_df)):\n",
    "    audio_file = data_path + train_df.loc[idx, 'filename']\n",
    "    aud, sr = torchaudio.load(audio_file) \n",
    "    train_audios.append(aud)\n",
    "\n",
    "for idx in range(len(val_df)):\n",
    "    audio_file = data_path + val_df.loc[idx, 'filename']\n",
    "    aud, sr = torchaudio.load(audio_file)\n",
    "    val_audios.append(aud)\n",
    "\n",
    "for idx in range(len(test_df)):\n",
    "    audio_file = data_path_test + test_df.loc[idx, 'filename']\n",
    "    aud, sr = torchaudio.load(audio_file) \n",
    "    test_audios.append(aud)\n",
    "    test_labels.append(test_df.loc[idx, 'is_normal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sgram (sgram, n_split=10):\n",
    "    sgrams = []\n",
    "    shape = sgram.shape[0]\n",
    "    for idx in range(n_split):\n",
    "        len = int(shape/10)\n",
    "        new_sgram = sgram[len*idx:len*idx + len, :]\n",
    "        sgrams.append(new_sgram)\n",
    "    return sgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchaudio import transforms\n",
    "spectrogram = False\n",
    "if spectrogram:\n",
    "    mel = transforms.MelSpectrogram(n_mels=128, n_fft=1000, hop_length=501)\n",
    "    ampl = transforms.AmplitudeToDB(top_db=80)\n",
    "\n",
    "    train_dataset = []\n",
    "    val_dataset = []\n",
    "    test_dataset = []\n",
    "\n",
    "\n",
    "\n",
    "    #Data preprocessing\n",
    "    for idx in range(len(train_audios)):\n",
    "        spec = mel(train_audios[idx])\n",
    "        spec = ampl(spec).mT\n",
    "        specs = split_sgram(spec.squeeze(0))\n",
    "        for spec in specs:\n",
    "            train_dataset.append(spec.reshape(-1))\n",
    "\n",
    "    for idx in range(len(val_audios)):\n",
    "        spec = mel(val_audios[idx])\n",
    "        spec = ampl(spec).mT\n",
    "        specs = split_sgram(spec.squeeze(0))\n",
    "        for spec in specs:\n",
    "            val_dataset.append(spec.reshape(-1))\n",
    "\n",
    "    for idx in range(len(test_audios)):\n",
    "        spec = mel(test_audios[idx])\n",
    "        spec = ampl(spec).mT\n",
    "        specs = split_sgram(spec.squeeze(0))\n",
    "        test_dataset.append([spec.reshape(-1) for spec in specs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def extract_mfccs(audio, n_mfcc=13, sr=16000, hop_length=512, n_fft=2048):\n",
    "    \n",
    "    # Extract MFCCs\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc, hop_length=hop_length, n_fft=n_fft)\n",
    "    \n",
    "    # Compute mean and variance for each MFCC coefficient over all frames\n",
    "    mfccs_mean = np.mean(mfccs, axis=1)\n",
    "    mfccs_var = np.var(mfccs, axis=1)\n",
    "    \n",
    "    # Combine mean and variance into a single feature vector\n",
    "    mfccs_features = np.concatenate((mfccs_mean, mfccs_var))\n",
    "    \n",
    "    return mfccs_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc = True\n",
    "if mfcc:\n",
    "\n",
    "    train_dataset = []\n",
    "    val_dataset = []\n",
    "    test_dataset = []\n",
    "\n",
    "    for idx in range(len(train_audios)):\n",
    "        features = extract_mfccs(np.array(train_audios[idx].squeeze(0)))\n",
    "        train_dataset.append(features)\n",
    "\n",
    "    for idx in range(len(val_audios)):\n",
    "        features = extract_mfccs(np.array(val_audios[idx].squeeze(0)))\n",
    "        val_dataset.append(features)\n",
    "\n",
    "    for idx in range(len(test_audios)):\n",
    "        features = extract_mfccs(np.array(test_audios[idx].squeeze(0)))\n",
    "        test_dataset.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2370, 52)\n",
      "(0,)\n",
      "(1101, 52)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = np.array(train_dataset)\n",
    "val_dataset = np.array(val_dataset)\n",
    "test_dataset = np.array(test_dataset)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "print(train_dataset.shape)\n",
    "print(val_dataset.shape)\n",
    "print(test_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca = PCA(n_components=10)\n",
    "#pca.fit(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset = pca.transform(train_dataset)\n",
    "#test_dataset = pca.transform(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1101,)\n",
      "full, 1, AUC: 0.858501872659176\n",
      "(1101,)\n",
      "full, 2, AUC: 0.8548938826466919\n",
      "(1101,)\n",
      "full, 3, AUC: 0.8588472742405328\n",
      "(1101,)\n",
      "full, 4, AUC: 0.857070328755722\n",
      "(1101,)\n",
      "full, 5, AUC: 0.8718934665002082\n",
      "(1101,)\n",
      "full, 6, AUC: 0.8696088223054514\n",
      "(1101,)\n",
      "full, 7, AUC: 0.871552226383687\n",
      "(1101,)\n",
      "full, 8, AUC: 0.8820640865584687\n",
      "(1101,)\n",
      "full, 9, AUC: 0.8535330836454432\n",
      "(1101,)\n",
      "full, 10, AUC: 0.8600499375780276\n",
      "(1101,)\n",
      "full, 11, AUC: 0.8474864752392841\n",
      "(1101,)\n",
      "full, 12, AUC: 0.8638160632542656\n",
      "(1101,)\n",
      "full, 13, AUC: 0.8415272575946735\n",
      "(1101,)\n",
      "full, 14, AUC: 0.8326799833541407\n",
      "(1101,)\n",
      "full, 15, AUC: 0.8374739908447774\n",
      "(1101,)\n",
      "full, 16, AUC: 0.8489596337910943\n",
      "(1101,)\n",
      "tied, 1, AUC: 0.858501872659176\n",
      "(1101,)\n",
      "tied, 2, AUC: 0.8620016645859342\n",
      "(1101,)\n",
      "tied, 3, AUC: 0.8592925509779443\n",
      "(1101,)\n",
      "tied, 4, AUC: 0.857070328755722\n",
      "(1101,)\n",
      "tied, 5, AUC: 0.8730586766541824\n",
      "(1101,)\n",
      "tied, 6, AUC: 0.8737786100707448\n",
      "(1101,)\n",
      "tied, 7, AUC: 0.8747523928422805\n",
      "(1101,)\n",
      "tied, 8, AUC: 0.8574157303370787\n",
      "(1101,)\n",
      "tied, 9, AUC: 0.8528880565959218\n",
      "(1101,)\n",
      "tied, 10, AUC: 0.859692051602164\n",
      "(1101,)\n",
      "tied, 11, AUC: 0.8575322513524762\n",
      "(1101,)\n",
      "tied, 12, AUC: 0.8562921348314608\n",
      "(1101,)\n",
      "tied, 13, AUC: 0.8560923845193509\n",
      "(1101,)\n",
      "tied, 14, AUC: 0.851718684977112\n",
      "(1101,)\n",
      "tied, 15, AUC: 0.8383936745734497\n",
      "(1101,)\n",
      "tied, 16, AUC: 0.8489596337910945\n",
      "(1101,)\n",
      "diag, 1, AUC: 0.858501872659176\n",
      "(1101,)\n",
      "diag, 2, AUC: 0.8620016645859342\n",
      "(1101,)\n",
      "diag, 3, AUC: 0.8592051602163961\n",
      "(1101,)\n",
      "diag, 4, AUC: 0.856629213483146\n",
      "(1101,)\n",
      "diag, 5, AUC: 0.8753058676654184\n",
      "(1101,)\n",
      "diag, 6, AUC: 0.8730586766541821\n",
      "(1101,)\n",
      "diag, 7, AUC: 0.8758718268830629\n",
      "(1101,)\n",
      "diag, 8, AUC: 0.8652808988764045\n",
      "(1101,)\n",
      "diag, 9, AUC: 0.8664336246358718\n",
      "(1101,)\n",
      "diag, 10, AUC: 0.8616687473990845\n",
      "(1101,)\n",
      "diag, 11, AUC: 0.853753641281731\n",
      "(1101,)\n",
      "diag, 12, AUC: 0.8576529338327089\n",
      "(1101,)\n",
      "diag, 13, AUC: 0.8391052850603413\n",
      "(1101,)\n",
      "diag, 14, AUC: 0.8459717020391178\n",
      "(1101,)\n",
      "diag, 15, AUC: 0.8459966708281316\n",
      "(1101,)\n",
      "diag, 16, AUC: 0.840374531835206\n"
     ]
    }
   ],
   "source": [
    "frames = False\n",
    "if not frames:\n",
    "    for covariance_type in ['full', 'tied', 'diag']:\n",
    "        for n_components in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]:\n",
    "            scores = []\n",
    "            gmm = GaussianMixture(n_components=n_components)\n",
    "            gmm.fit(train_dataset)\n",
    "            scores = gmm.score_samples(test_dataset)\n",
    "            print(scores.shape)\n",
    "            fpr, tpr, _ = roc_curve(test_labels, scores, pos_label=1)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            val_likelihood = gmm.score(val_dataset)\n",
    "            print(f'{covariance_type}, {n_components}, AUC: {roc_auc}, Val Likelihood: {val_likelihood}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "if frames:\n",
    "    for covariance_type in ['full', 'tied', 'diag']:\n",
    "        for n_components in [1, 2, 3, 4]:\n",
    "            scores = []\n",
    "            gmm = GaussianMixture(n_components=n_components)\n",
    "            gmm.fit(train_dataset)\n",
    "            for test_sample in test_dataset:\n",
    "                test = np.array(test_sample)\n",
    "                #test = pca.transform(test)\n",
    "                predictions = gmm.score_samples(test)\n",
    "                scores.append(np.min(predictions))\n",
    "            print(scores)\n",
    "            fpr, tpr, _ = roc_curve(test_labels, scores, pos_label=1)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "        print(f'{covariance_type}, {n_components}, AUC: {roc_auc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
